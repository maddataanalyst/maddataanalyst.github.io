[{"authors":null,"categories":null,"content":"Hello!\nMy name is Filip W√≥jcik and I‚Äôm a data scientist and a programmer with specialization in artificial intelligence and machine learning. Recently I have also become a Ph.D. at the Wroclaw University of Economics, IT in Economics Institute, faculty of Business Intelligence in Management. I‚Äôve also graduated as a lawyer but‚Ä¶ well‚Ä¶ everybody makes mistakes, so let‚Äôs skip this part üôÇ\nMachine learning and matters related with data science are my hobby, professional activity and the most important research area. I believe, that I‚Äôve found (so often discussed) balance between those main life areas. Now I try to share my passion with students and all interested people during conferences and lectures. This website was designed to be a platform to share educational materials and my research papers findings.\nApart from that ‚Äì I‚Äôm a happy husband, keeper of two lovely kittens and sports fanatic ‚Äì starting from (so popular now) CrossFit, through martial arts (2nd Dan Aikido, self-defense instructor and Krav Maga prcaticioner) ending up with mountains tourism.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"09e76bc8aaace0e678c41d60b331ee4d","permalink":"https://maddataanalyst.github.io/en/authors/filip/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/filip/","section":"authors","summary":"Hello!\nMy name is Filip W√≥jcik and I‚Äôm a data scientist and a programmer with specialization in artificial intelligence and machine learning. Recently I have also become a Ph.D. at the Wroclaw University of Economics, IT in Economics Institute, faculty of Business Intelligence in Management.","tags":null,"title":"Filip W√≥jcik","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  About category Posts in this category    About category This section covers various topics on Recurrent Neural Networks and their variance.\nWhile Convolutional networks (CNNs) seem to be very intuitive, some people have a hard time understanding the LSTM, GRU, or attention mechanisms. Posts in this category will try to explain at least some of the more complex concepts.\nPosts in this category  Fifty Shades of Time: Time series \u0026amp; RNNs Time series processing is a well-known and extensively researched problem. Moreover - many people naturally understand, what a time series is, and how it is structured. Things start to get complicated once you are about to prepare time-dependent data for modeling with neural networks. Three-dimensional structures are not that easy to imagine initially.\n  ","date":1621123200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1621123200,"objectID":"d624f3ee0dbc3e3a523ca1a50e1aa281","permalink":"https://maddataanalyst.github.io/en/post/rnns/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/en/post/rnns/","section":"post","summary":"Section about various Recurrent Neural Network variants.","tags":null,"title":"üìä RNNs","type":"book"},{"authors":["Filip W√≥jcik"],"categories":["Tutorials","Time series","RNN"],"content":"Part 1: univariate time series + classification           Image by Gerd Altmann from Pixabay    Intro Time series processing is a well-known and extensively researched problem. Moreover - many people naturally understand, what a time series is, and how it is structured. Things start to get complicated once you are about to prepare time-dependent data for modeling with neural networks. Three-dimensional structures are not that easy to imagine initially. After reading this blog post, you will:\n Understand the data should be pre-processed for LSTM neural networks; Understand the benefits of keeping time-dependent structures in data; See a practical example of wrongly and correctly prepared data for LSTM. Technologies used in this post are: Pandas Numpy Tensorflow/Keras.  The code can be found: here.\nUnivariate ts Univariate time-series data is nothing more than a vector of scalar (single values) observations recorded sequentially [NIST/SEMATECH e-Handbook of Statistical Methods]. In typical use-case scenarios (like stock price modeling or evaluating some processes happening in real life), the vector is indexed by time: days, minutes, seconds, etc‚Ä¶ An example is presented below - a stock prices data, indexed by time and presented on a chart:\n   time value     2020-10-01 00:00:00 0.968858   2020-10-02 00:00:00 0.19665   2020-10-03 00:00:00 0.516261   2020-10-04 00:00:00 0.646792   2020-10-05 00:00:00 0.291559   2020-10-06 00:00:00 0.580785   2020-10-07 00:00:00 0.181799   2020-10-08 00:00:00 0.153987   2020-10-09 00:00:00 0.976227   2020-10-10 00:00:00 0.0599845    Libraries like Pandas have many functionalities related to time-series processing. Most of them are self-explanatory: you‚Äôre working with a flat vector of numbers. A detailed tutorial and explanations on this topic can be found in the official Pandas documentation.\nNeural networks \u0026amp; ts data Time-series data becomes problematic when we want to use it with neural networks. Of course, our goal is to keep the time-dependence, as we might believe, that it carries some important information.\nA family of neural networks (NN) architecture that is naturally designed to consume that kind of data is called ‚ÄúRecurrent Neural Networks‚Äù (RNN), nowadays mainly represented by Long-Short Term Memory (LSTM) or Gated-Recurrent Unit (GRU) NNs*.\n*We won‚Äôt discuss Transformers and Attention layers here, as they are players in their own league :)\nIn this post, we will discuss a classification task, so operation called: ‚Äúmany-to-one‚Äù. In this scenario, LSTM:\n Takes a time-series data as an input; Passes it step-by-step through the network; Predicts a given class.  flowchart LR\rlstmT -- y[y pred]\rsubgraph t[LSTM T0, T1, T2... T]\rstate[state 0] --LSTM1\rLSTM1 --LSTM2\rLSTM2 --LSTM3\rLSTM3 --lstm[LSTM...]\rlstm[LSTM...]-- lstmT[LSTM T]\rend\rx1 -- LSTM1\rx2 -- LSTM2\rx3 -- LSTM3\rx[x...] -- lstm\rxT -- lstmT  You can read more (and see some interesting visualizations) on the Stanford University CS230 Recurrent Neural Networks Course website [[Stanford CS 230 - Recurrent Neural Networks ])(#cs230)].\nNotation Before we proceed, let‚Äôs introduce some notation. It will be much easier to operate on symbols instead of describing everything in words :)\n$$ \\begin{align*} N -\u0026amp; \\text{ number of time windows (samples) to consider} \u0026amp; \\\\\\ y_i^t -\u0026amp; \\text{ observation in the moment t, that belongs to ith sample} \u0026amp; \\\\\\ T -\u0026amp; \\text{ maximal time-window size} \u0026amp; \\\\\\ h -\u0026amp; \\text{ LSTM units} \u0026amp; \\\\\\ c -\u0026amp; \\text{ number of classes} \u0026amp; \\\\\\ f -\u0026amp; \\text{ number of features (unique time series) to use} \\end{align*} $$\nIn this tutorial, we will operate on univariate time series, so f=1 every time\nData structures LSTMs require a particular data format that preserves a time-dependence and keeps data at least three-dimensional. What a typical LSTM network need is the following shape:\n$$ N \\times T \\times F $$\nSo a three-dimensional structure: no. of samples x time steps x features (=1 in this tutorial).\nYou might wonder - ‚Äúwhat are these samples? How do we get samples from a time series? How do I know how many steps I should have?‚Äù. Let‚Äôs first discuss this problem theoretically and then - use some concrete, practical examples.\nChoosing shape How do we decide on the number of time steps T in our structure? Most of the time, it should be an ‚Äúinformed guess‚Äù. Number T will determine how large a piece of a time series the LSTM will receive in one go. In other words - how far-seeing will it be. The decision should be based on either:\n The properties of the time series - seasonality, autocorrelation, trends, etc. How large is the period needed to capture some relevant info? You can obtain such information by classic time-series decomposition using statistical analysis. The business rationale behind the process - e.g., preexisting knowledge about the most informative length of the sequence (the typical length of the business process or seasonality of an event). Previous studies or research presenting the optimal window size for a ‚Ä¶","date":1652659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652659200,"objectID":"df24a3a4b2a9a02f57ca56366ac109dc","permalink":"https://maddataanalyst.github.io/en/post/rnns/fifty-shapes-of-time/","publishdate":"2022-05-16T00:00:00Z","relpermalink":"/en/post/rnns/fifty-shapes-of-time/","section":"post","summary":"Time series processing is a well-known and extensively researched problem. Moreover - many people naturally understand, what a time series is, and how it is structured. Things start to get complicated once you are about to prepare time-dependent data for modeling with neural networks. Three-dimensional structures are not that easy to imagine initially.","tags":["Deep Learning","Time-series","RNN"],"title":"Fifty Shades of Time: Time series \u0026 RNNs","type":"book"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"","date":1614631001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614631001,"objectID":"57b2a5189d93ba30ce00c54bc904dae9","permalink":"https://maddataanalyst.github.io/en/publication/beyond_a_barrier_of_mistrust/","publishdate":"2021-03-01T21:36:41+01:00","relpermalink":"/en/publication/beyond_a_barrier_of_mistrust/","section":"publication","summary":"Presentation of modern explainable artificial intelligence approaches.","tags":["deep learning","xai"],"title":"Beyond the barrier of mistrust ‚Äì an overview of selected methods for explaining predictions of machine learning models","type":"publication"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"","date":1614631001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614631001,"objectID":"32abb917ee6895acf66a9acec07d76fe","permalink":"https://maddataanalyst.github.io/en/publication/deep_learning_as_recommenders/","publishdate":"2021-03-01T21:36:41+01:00","relpermalink":"/en/publication/deep_learning_as_recommenders/","section":"publication","summary":"Presentation of modern architectures of deep learning algorithms as recommendation engines","tags":["deep learning","recommendation systems"],"title":"Usage of deep neural networks as recommendation engines. Review of selected approaches","type":"publication"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"The goal of this presentation and associated paper is to present results of investigation related to use of the Extreme Gradient Boosting XGBoost algorithm as a forecasting tool. The data provided by the Rossman Com-pany, with a request to design an innovative prediction method, has been used as a base for this case study. The data contains details about micro- and macro-environment, as well as turnover of 1115 stores. Performance of the algorithm was compared to classical forecasting models SARIMAX and Holt-Winters, using time-series cross validation and tests for statistical importance in prediction quality dif-ferences. Metrics of root mean squared percentage error (RMSPE), Theil‚Äôs coeffi-cient and adjusted correlation coefficient were analyzed. Results where then passed to Rossman for verification on a separate validation set, via Kaggle.com platform. Study results confirmed, that XGBoost, after using proper data preparation and training method, achieves better results than classical models.\n","date":1592481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592481600,"objectID":"30dcaef84e30b907fd8b696aef5cad0d","permalink":"https://maddataanalyst.github.io/en/talk/one-concept-to-rule-them-all-uses-of-neural-embeddings-beyond-natural-language-processing/","publishdate":"2020-06-18T12:00:00Z","relpermalink":"/en/talk/one-concept-to-rule-them-all-uses-of-neural-embeddings-beyond-natural-language-processing/","section":"event","summary":"Neural embeddings are one of the most popular techniques used in Natural Language Processing to represent word similarities. There are many variations and implementations of this concept - starting from skip-gram, through GloVe or Word2Vec. But embeddings are a much more powerful concept that can be utilized in many different areas, not only NLP. Possible applications of embeddings in recommendation engines, item similarity detection, and market basket analysis through frequent items search will be presented during this speech.","tags":["Deep Learning","recommendation systems"],"title":"One concept to rule them all - uses of neural embeddings beyond natural language processing","type":"event"},{"authors":["Filip W√≥jcik","Micha≈Ç G√≥rnik"],"categories":null,"content":"","date":1583267801,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583267801,"objectID":"202bc887224d3c04096d105fa7d1432c","permalink":"https://maddataanalyst.github.io/en/publication/deep_hybrid_recommendation_system/","publishdate":"2020-03-03T21:36:41+01:00","relpermalink":"/en/publication/deep_hybrid_recommendation_system/","section":"publication","summary":"A presentation of new algorithm for recommendations with hybrid deep learning architecture","tags":["deep learning","recommendation systems"],"title":"Improvement of e-commerce recommendation systems with deep hybrid collaborative filtering with content: A case study","type":"publication"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"Recommendation engines are probably the most important tools for modern e-commerce organizations. As the data volumes grow larger and larger (as well as product/user base), traditional approaches based on collaborative might be not enough. During this talk I will present alternative approaches to recommendations - making use of deep stacked autoencoders.\n","date":1560513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560513600,"objectID":"b89daa788f5be9edfbcc9dd933dd10d7","permalink":"https://maddataanalyst.github.io/en/talk/recommendation-engines-based-on-autoencoders/","publishdate":"2019-06-14T12:00:00Z","relpermalink":"/en/talk/recommendation-engines-based-on-autoencoders/","section":"event","summary":"How autoencoders can be used as recommendation engines, replacing collaborative filtering or other approaches.","tags":["deep learning","recommendation systems"],"title":"Recommendation engines based on autoencoders","type":"event"},{"authors":null,"categories":null,"content":"A series of presentations, publications and implementations of deep learning algorithms as recommendation engines.\n","date":1560470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560470400,"objectID":"7de7ee5edf00135a3351dc6cb4015c88","permalink":"https://maddataanalyst.github.io/en/project/deep_learning_recommenders/","publishdate":"2019-06-14T00:00:00Z","relpermalink":"/en/project/deep_learning_recommenders/","section":"project","summary":"A series of presentations, publications and implementations of deep learning algorithms as recommendation engines.","tags":["Deep Learning","recommendation systems"],"title":"Deep Learning usage as recommendation engine","type":"project"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"The goal of this presentation and associated paper is to present results of investigation related to use of the Extreme Gradient Boosting XGBoost algorithm as a forecasting tool. The data provided by the Rossman Com-pany, with a request to design an innovative prediction method, has been used as a base for this case study. The data contains details about micro- and macro-environment, as well as turnover of 1115 stores. Performance of the algorithm was compared to classical forecasting models SARIMAX and Holt-Winters, using time-series cross validation and tests for statistical importance in prediction quality dif-ferences. Metrics of root mean squared percentage error (RMSPE), Theil‚Äôs coeffi-cient and adjusted correlation coefficient were analyzed. Results where then passed to Rossman for verification on a separate validation set, via Kaggle.com platform. Study results confirmed, that XGBoost, after using proper data preparation and training method, achieves better results than classical models.\n","date":1528459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528459200,"objectID":"c2f97d35cd05ba5ee4a11cb75d04f3c1","permalink":"https://maddataanalyst.github.io/en/talk/xgboost-as-a-time-series-forecasting-tool/","publishdate":"2018-06-08T12:00:00Z","relpermalink":"/en/talk/xgboost-as-a-time-series-forecasting-tool/","section":"event","summary":"can we use XGBoost as a time-series forecasting tool?","tags":["machine learning","forecasting"],"title":"XGBoost as a time-series forecasting tool","type":"event"},{"authors":null,"categories":null,"content":"A series of publications, conference talks and other materials, related to the usage of XGBoost as a financial forecasting tool.\n","date":1528416000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528416000,"objectID":"d678f39e2a9e48ee90698fa0aeb81683","permalink":"https://maddataanalyst.github.io/en/project/xgboost_forecast/","publishdate":"2018-06-08T00:00:00Z","relpermalink":"/en/project/xgboost_forecast/","section":"project","summary":"A series of presentations and publications about time-series forecasting with XGBoost tool","tags":["forecasting","xgboost"],"title":"Forecasting with XGboost","type":"project"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"Human capital and human resources are key success factors for multiple knowledge-based companies. Managing competences of employees is one of the most important areas for modern management science. This paper presents, an innovative algorithm based on natural language processing (NLP) and association analysis for recognition, assignment and evaluation of competences in a knowledge-rich organizations. An algorithm performs keywords extraction from applicant‚Äôs and employees resumes, which are used later on in a supervised phase. Achieved results - 71% of balanced accuracy in a case study suggest, that a system can recognize important correlations between competences and assigned projects.\n","date":1524052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524052800,"objectID":"b9a13e1e1497a2742d6d3ca59cb051dd","permalink":"https://maddataanalyst.github.io/en/talk/machine-learning-and-artificial-intelligence-as-a-decision-support-systems-for-human-capital-management/","publishdate":"2018-04-18T12:00:00Z","relpermalink":"/en/talk/machine-learning-and-artificial-intelligence-as-a-decision-support-systems-for-human-capital-management/","section":"event","summary":"How can machine learning help in managing human resources in organizations?","tags":["machine learning"],"title":"Machine learning and artificial intelligence as a decision support systems for human capital management","type":"event"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519862400,"objectID":"d59f0b066df46317beaeb89b7cf3bbc6","permalink":"https://maddataanalyst.github.io/en/publication/xgboost_turnover/","publishdate":"2018-03-01T00:00:00Z","relpermalink":"/en/publication/xgboost_turnover/","section":"publication","summary":"Analysis of XGBoost applications to financial forecasting and sales management.","tags":["xgboost","forecasting","econometrics"],"title":"Forecasting Daily Turnover Using Xgboost Algorithm ‚Äì A Case Study","type":"publication"},{"authors":["dr hab. Iwona Chomiak-Orsa, prof. UE","Filip W√≥jcik"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"3eaa1b65b4ee3d9467461f7d934fc250","permalink":"https://maddataanalyst.github.io/en/publication/business_relevant_attributes_2017/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/en/publication/business_relevant_attributes_2017/","section":"publication","summary":"Modern decision support systems make use of machine learning and artificial intelligence to solve complicated problems. One of them is classification, understood in this context as assigning objects to categories. Amongst many methods to achieve this goal, rulebased systems pay special attention, because they provide an end-user not only with direct answers to a given problem, but also produce useful insights into correlations present in a dataset. In this article new method has been proposed ‚àí application and modification of Leo Breiman‚Äôs original Random Forest solution combined with backwards elimination (known from classic regression) ‚àí and tested on real credit decisions dataset. Differences in classification metrics between base and augmented classifier were checked using cross-validation testing, and statistical significance. The article concludes with further research suggestions.","tags":["machine learning","operations research"],"title":"Detecting business-relevant attributes in rule-based classification","type":"publication"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"H2O AI is one of the most interesting out-of-the-box machine learning tools. It has plenty of algorithms implemented, those algorithms are really fast and effective and it integrates well with R and Spark. One of them is especially interesing - Gradient Boosting. Want to know more?\n","date":1491566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491566400,"objectID":"397adc297b22d692d52da27154ddceba","permalink":"https://maddataanalyst.github.io/en/talk/water-powered-machine-learning-gradient-boosting-machines-in-h2o-ai/","publishdate":"2017-04-07T12:00:00Z","relpermalink":"/en/talk/water-powered-machine-learning-gradient-boosting-machines-in-h2o-ai/","section":"event","summary":"H2O AI is one of the most interesting out-of-the-box machine learning tools. It has plenty of algorithms implemented, those algorithms are really fast and effective and it integrates well with R and Spark. One of them is especially interesing - Gradient Boosting. Want to know more?","tags":["machine learning"],"title":"Water powered machine learning: gradient boosting machines in H2O AI","type":"event"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"Machine learning algorithms are replacement for an old-fashioned advisory systems. How we can utilize them in such a way? How white-box systems are different from black-box?\n","date":1461844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461844800,"objectID":"674b63d3f34cffb89b7b41221f980905","permalink":"https://maddataanalyst.github.io/en/talk/decision-support-systems-remade-machine-learning-advisers/","publishdate":"2016-04-28T12:00:00Z","relpermalink":"/en/talk/decision-support-systems-remade-machine-learning-advisers/","section":"event","summary":"Machine learning algorithms are replacement for an old-fashioned advisory systems. How we can utilize them in such a way? How white-box systems are different from black-box?","tags":["machine learning"],"title":"Decision support systems remade: (machine) learning advisers","type":"event"},{"authors":["Filip W√≥jcik"],"categories":null,"content":"","date":1446724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446724800,"objectID":"1d0e54b5eb038a4f81b3fc4b7974d926","permalink":"https://maddataanalyst.github.io/en/talk/machine-learning-when-big-data-is-not-enough/","publishdate":"2015-11-05T12:00:00Z","relpermalink":"/en/talk/machine-learning-when-big-data-is-not-enough/","section":"event","summary":"Presentation of various machine learning capabilities, as a tools to make sense out of large datasets","tags":["machine learning"],"title":"Machine learning - when Big Data is not enough","type":"event"}]