<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.5.0 for Hugo" />
  

  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Filip WÃ³jcik" />

  
  
  
    
  
  <meta name="description" content="Time series processing is a well-known and extensively researched problem. Moreover - many people naturally understand, what a time series is, and how it is structured. Things start to get complicated once you are about to prepare time-dependent data for modeling with neural networks. Three-dimensional structures are not that easy to imagine initially." />

  
  <link rel="alternate" hreflang="en-us" href="https://maddataanalyst.github.io/en/post/rnns/fifty-shapes-of-time/" />

  
  
  
    <meta name="theme-color" content="#1565c0" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
    
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.978ed78d787744677cc3f4f1579d21c3.css" />

  



  


  


  




  
  
  

  

  
    <link rel="manifest" href="/en/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://maddataanalyst.github.io/en/post/rnns/fifty-shapes-of-time/" />

  
  
  
  
  
  
  
  
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="NeuraSYS" />
  <meta property="og:url" content="https://maddataanalyst.github.io/en/post/rnns/fifty-shapes-of-time/" />
  <meta property="og:title" content="Fifty Shades of Time: Time series &amp; RNNs | NeuraSYS" />
  <meta property="og:description" content="Time series processing is a well-known and extensively researched problem. Moreover - many people naturally understand, what a time series is, and how it is structured. Things start to get complicated once you are about to prepare time-dependent data for modeling with neural networks. Three-dimensional structures are not that easy to imagine initially." /><meta property="og:image" content="https://maddataanalyst.github.io/en/post/rnns/fifty-shapes-of-time/featured.jpg" />
    <meta property="twitter:image" content="https://maddataanalyst.github.io/en/post/rnns/fifty-shapes-of-time/featured.jpg" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-05-16T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-05-16T00:00:00&#43;00:00">
  

  



  

  

  





  <title>Fifty Shades of Time: Time series &amp; RNNs | NeuraSYS</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="df24a3a4b2a9a02f57ca56366ac109dc" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.e22a2a20712150175b9cd707be2d0584.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<header class="header--fixed">
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/en/">NeuraSYS</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/en/">NeuraSYS</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#talks"><span>Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#featured"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#post"><span>Recent posts</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/en/post"><span>Blog</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    




<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      <form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <div class="d-flex">
      <span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">
        
        
          RNNS
        
      </span>
      <span><i class="fas fa-chevron-down"></i></span>
    </div>
  </button>

  
  <button class="form-control sidebar-search js-search d-none d-md-flex">
    <i class="fas fa-search pr-2"></i>
    <span class="sidebar-search-text">Search...</span>
    <span class="sidebar-search-shortcut">/</span>
  </button>
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  
  
  
  

  
  
    

    
      

      <ul class="nav docs-sidenav">
        <li><a href="/en/post/"><i class="fas fa-arrow-left pr-1"></i>ðŸ“š Posts</a></li>
      </ul>

      
      
        
          
        
      


  
    
    
    
    
      
    
    

    
      <div class="docs-toc-item">
        <a class="docs-toc-link " href="/en/post/rnns/">RNNS</a>
    
      
        <ul class="nav docs-sidenav">
      


  <li class="active"><a href="/en/post/rnns/fifty-shapes-of-time/">Fifty Shades of Time: Time series &amp; RNNs</a></li>

      
        </ul>
      
    

    
      </div>
    

    
  
</nav>

    </div>

    
    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      

      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#univariate-ts">Univariate ts</a></li>
    <li><a href="#neural-networks--ts-data">Neural networks &amp; ts data</a></li>
    <li><a href="#notation">Notation</a></li>
    <li><a href="#data-structures">Data structures</a></li>
    <li><a href="#choosing-shape">Choosing shape</a></li>
    <li><a href="#slicing">Slicing</a></li>
    <li><a href="#lstm-prep">LSTM prep</a></li>
    <li><a href="#practical-example">Practical example</a>
      <ul>
        <li><a href="#the-problem">The problem</a></li>
        <li><a href="#the-data">The data</a></li>
        <li><a href="#the-experiment">The experiment</a></li>
        <li><a href="#wrong-approach">Wrong approach</a></li>
      </ul>
    </li>
    <li><a href="#summary">Summary</a></li>
    <li><a href="#bibliography">Bibliography</a></li>
  </ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article">

        <div class="docs-article-container">
          
        </div>

        
        

        <div class="docs-article-container">
          <h1>Fifty Shades of Time: Time series &amp; RNNs</h1>

          <div class="article-style">
            <h1 id="part-1-univariate-time-series--classification">Part 1: univariate time series + classification</h1>
<table>
<thead>
<tr>
<th style="text-align:center">















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="featured.jpg" srcset="
               /en/post/rnns/fifty-shapes-of-time/featured_hu79560c43f3f88bfda1ea41b6ac12dbd3_751222_2e2bbcbd832ef94c53781ac449656622.webp 400w,
               /en/post/rnns/fifty-shapes-of-time/featured_hu79560c43f3f88bfda1ea41b6ac12dbd3_751222_c2aed99824a5e68753ff576c0b508db8.webp 760w,
               /en/post/rnns/fifty-shapes-of-time/featured_hu79560c43f3f88bfda1ea41b6ac12dbd3_751222_1200x1200_fit_q75_h2_lanczos.webp 1200w"
               src="/en/post/rnns/fifty-shapes-of-time/featured_hu79560c43f3f88bfda1ea41b6ac12dbd3_751222_2e2bbcbd832ef94c53781ac449656622.webp"
               width="760"
               height="507"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><b>Image by <a href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3222267">Gerd Altmann</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3222267">Pixabay</a></b></td>
</tr>
</tbody>
</table>
<h2 id="intro">Intro</h2>
<p>Time series processing is a well-known and extensively researched problem. Moreover - many people naturally understand, what a time series is, and how it is structured. Things start to get complicated once you are about to prepare time-dependent data for modeling with neural networks. Three-dimensional structures are not that easy to imagine initially.
After reading this blog post, you will:</p>
<ol>
<li>Understand the data should be pre-processed for LSTM neural networks;</li>
<li>Understand the benefits of keeping time-dependent structures in data;</li>
<li>See a practical example of wrongly and correctly prepared data for LSTM.
Technologies used in this post are:</li>
<li>Pandas</li>
<li>Numpy</li>
<li>Tensorflow/Keras.</li>
</ol>
<p>The code can be found: <a href="https://github.com/maddataanalyst/blogposts_code/tree/main/fifty_shapes_of_time" target="_blank" rel="noopener">here</a>.</p>
<h2 id="univariate-ts">Univariate ts</h2>
<p>Univariate time-series data is nothing more than a vector of scalar (single values) observations recorded sequentially [<a href="#handbook">NIST/SEMATECH e-Handbook of Statistical Methods</a>]. In typical use-case scenarios (like stock price modeling or evaluating some processes happening in real life), the vector is indexed by time: days, minutes, seconds, etc&hellip; An example is presented below - a stock prices data, indexed by time and presented on a chart:</p>
<table>
<thead>
<tr>
<th style="text-align:left">time</th>
<th style="text-align:right">value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">2020-10-01 00:00:00</td>
<td style="text-align:right">0.968858</td>
</tr>
<tr>
<td style="text-align:left">2020-10-02 00:00:00</td>
<td style="text-align:right">0.19665</td>
</tr>
<tr>
<td style="text-align:left">2020-10-03 00:00:00</td>
<td style="text-align:right">0.516261</td>
</tr>
<tr>
<td style="text-align:left">2020-10-04 00:00:00</td>
<td style="text-align:right">0.646792</td>
</tr>
<tr>
<td style="text-align:left">2020-10-05 00:00:00</td>
<td style="text-align:right">0.291559</td>
</tr>
<tr>
<td style="text-align:left">2020-10-06 00:00:00</td>
<td style="text-align:right">0.580785</td>
</tr>
<tr>
<td style="text-align:left">2020-10-07 00:00:00</td>
<td style="text-align:right">0.181799</td>
</tr>
<tr>
<td style="text-align:left">2020-10-08 00:00:00</td>
<td style="text-align:right">0.153987</td>
</tr>
<tr>
<td style="text-align:left">2020-10-09 00:00:00</td>
<td style="text-align:right">0.976227</td>
</tr>
<tr>
<td style="text-align:left">2020-10-10 00:00:00</td>
<td style="text-align:right">0.0599845</td>
</tr>
</tbody>
</table>
<p>Libraries like Pandas have many functionalities related to time-series processing. Most of them are self-explanatory: you&rsquo;re working with a flat vector of numbers. A detailed tutorial and explanations on this topic can be found in the official <a href="https://pandas.pydata.org/docs/user_guide/timeseries.html" target="_blank" rel="noopener">Pandas documentation</a>.</p>
<h2 id="neural-networks--ts-data">Neural networks &amp; ts data</h2>
<p>Time-series data becomes problematic when we want to use it with neural networks. Of course, our goal is to keep the time-dependence, as we might believe, that it carries some important information.</p>
<p>A family of neural networks (NN) architecture that is naturally designed to consume that kind of data is called &ldquo;Recurrent Neural Networks&rdquo; (RNN), nowadays mainly represented by Long-Short Term Memory (LSTM) or Gated-Recurrent Unit (GRU) NNs*.</p>
<p>*We won&rsquo;t discuss Transformers and Attention layers here, as they are players in their own league :)</p>
<p>In this post, we will discuss a classification task, so operation called: &ldquo;many-to-one&rdquo;. In this scenario, LSTM:</p>
<ol>
<li>Takes a time-series data as an input;</li>
<li>Passes it step-by-step through the network;</li>
<li>Predicts a given class.</li>
</ol>
<div class="mermaid">flowchart LR
    lstmT --> y[y pred]
    subgraph t[LSTM T0, T1, T2... T]
      state[state 0] -->LSTM1
      LSTM1 -->LSTM2
      LSTM2 -->LSTM3
      LSTM3 -->lstm[LSTM...]
      lstm[LSTM...]--> lstmT[LSTM T]
    end
    x1 --> LSTM1
    x2 --> LSTM2
    x3 --> LSTM3
    x[x...] --> lstm
    xT --> lstmT
</div>
<p>You can read more (and see some interesting visualizations) on the Stanford University CS230 Recurrent Neural Networks Course website [<a href="#cs230">Stanford CS 230 - Recurrent Neural Networks </a>].</p>
<h2 id="notation">Notation</h2>
<p>Before we proceed, let&rsquo;s introduce some notation. It will be much easier to operate on symbols instead of describing everything in words :)</p>
<p>$$
\begin{align*}
N -&amp; \text{ number of time windows (samples) to consider} &amp;  \\\
y_i^t -&amp; \text{ observation in the moment t, that belongs to ith sample} &amp;  \\\
T -&amp; \text{ maximal time-window size} &amp;  \\\
h -&amp; \text{ LSTM units} &amp;  \\\
c -&amp; \text{ number of classes} &amp;  \\\
f -&amp; \text{ number of features (unique time series) to use}
\end{align*}
$$</p>
<p>In this tutorial, we will operate on univariate time series, so f=1 every time</p>
<h2 id="data-structures">Data structures</h2>
<p>LSTMs require a particular data format that preserves a time-dependence and keeps data at least three-dimensional. What a typical LSTM network need is the following shape:</p>
<p>$$ N \times T \times F $$</p>
<p>So a three-dimensional structure: no. of samples x time steps x features (=1 in this tutorial).</p>
<p>You might wonder - &ldquo;what are these samples? How do we get samples from a time series? How do I know how many steps I should have?&rdquo;.
Let&rsquo;s first discuss this problem theoretically and then - use some concrete, practical examples.</p>
<h2 id="choosing-shape">Choosing shape</h2>
<p>How do we decide on the number of time steps T in our structure? Most of the time, it should be an &ldquo;informed guess&rdquo;. Number T will determine how large a piece of a time series the LSTM will receive in one go. In other words - how far-seeing will it be. The decision should be based on either:</p>
<ol>
<li><strong>The properties of the time series</strong> - seasonality, autocorrelation, trends, etc. How large is the period needed to capture some relevant info? You can obtain such information by classic time-series decomposition using statistical analysis.</li>
<li><strong>The business rationale behind the process</strong> - e.g., preexisting knowledge about the most informative length of the sequence (the typical length of the business process or seasonality of an event).</li>
<li><strong>Previous studies or research</strong> presenting the optimal window size for a similar problem (e.g., time exposure to some stimulus).</li>
</ol>
<p>However, you must be aware that classic recurrent neural networks, LSTMs, and GRUs are prone to vanishing or exploding gradients if the sequences are large. If the time window is too large, LSTM might start to &ldquo;forget&rdquo; what it has seen so far, leading (of course) to worsening the prediction results. This vulnerability is one of the reasons why special training techniques (like Truncated Backpropagation Through Time (TBTT) or Gradient Clipping) and architectures (attention layers and eventually Transformers) were designed.
Although theoretically, LSTMs can handle sequences spanning a couple of hundred elements, it is better to shorten them and present in the form of limited-time windows [<a href="#mikolov">Mikolov, et al. 2013</a>; <a href="#karpathy">Karpathy, 2015</a>].</p>
<h2 id="slicing">Slicing</h2>
<p>Once we have decided the length of our time window, it is time to slice a time series. The operation is easy and relatively intuitive: we slide a window of size T, one element at a time, and save subsequent windows as samples. This is the way we obtain N samples.</p>
<p>It is easy to calculate the number of time-slices: it will be <code>(K-T+1)</code>.</p>
<p>Let&rsquo;s check if that&rsquo;s true.</p>
<p>Imagine that we have:</p>
<ul>
<li>A time series of consecutive numbers from 0 to 90.</li>
<li>They are indexed by dates from 01.01.2020 to 31.03.2020.</li>
<li>We want to have a sliding time window of size 6.</li>
</ul>
<p>Therefore in our calculation we will have:
$$ K = 91 $$
$$ T = 6 $$
$$ N = (K-T+1) = 86 $$</p>
<p>The code snipped below presents:</p>
<ol>
<li>How to construct such a time series.</li>
<li>How to slice it using pandas.</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_lagged_data</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">k_lags</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Generates a lagged time series data in a fromat y, y-1, y-2, ..., y-K up to
</span></span></span><span class="line"><span class="cl"><span class="s2">    K-th lag.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Parameters
</span></span></span><span class="line"><span class="cl"><span class="s2">    ----------
</span></span></span><span class="line"><span class="cl"><span class="s2">    y : pd.Series
</span></span></span><span class="line"><span class="cl"><span class="s2">        Original time series.
</span></span></span><span class="line"><span class="cl"><span class="s2">    k_lags: int
</span></span></span><span class="line"><span class="cl"><span class="s2">        Number of lags to generate.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns
</span></span></span><span class="line"><span class="cl"><span class="s2">    ----------
</span></span></span><span class="line"><span class="cl"><span class="s2">    pd.DataFrame
</span></span></span><span class="line"><span class="cl"><span class="s2">        A lagged dataframe in format y, y-1, y-2, ..., y-K.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k_lags</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">fname</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;y-</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&#34;</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&#34;y&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">lagged</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="n">fname</span><span class="p">]</span> <span class="o">=</span> <span class="n">lagged</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">example_ts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">generate_lagged_data</span><span class="p">(</span><span class="n">example_ts</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>Output from this function looks like this:</p>
<table>
<thead>
<tr>
<th>y Â  Â  Â </th>
<th>y-1  Â  Â  Â </th>
<th>y-2 Â  Â  Â </th>
<th>y-3 Â  Â Â </th>
<th>y-4 Â  Â Â </th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>7</td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
</tr>
<tr>
<td>8</td>
<td>7</td>
<td>6</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>9</td>
<td>8</td>
<td>7</td>
<td>6</td>
<td>5</td>
</tr>
</tbody>
</table>
<h2 id="lstm-prep">LSTM prep</h2>
<p>There is one more thing missing. As described above, LSTM expects the data in the following format:
$$ N \times K \times f $$</p>
<p>where f is a number of features. In our case, f = 1 because we want to analyze only one time series. So, we can use numpy&rsquo;s <code>expand_dims</code> function to add this one missing dimension:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">lagged_example_for_lstm</span> <span class="o">=</span> <span class="n">lagged_example</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">lagged_example</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_example_for_lstm</span><span class="o">.</span><span class="n">shape</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>As we can see, now the shape is ready to be utilized with an LSTM network.</p>
<h2 id="practical-example">Practical example</h2>
<h3 id="the-problem">The problem</h3>
<p>Let&rsquo;s imagine the following situation: we have three different processes, logging some information over time. These might be some sensors, loggers, or robots; details do not matter. Each of these traces has a different characteristic and morphology of a signal.</p>
<h3 id="the-data">The data</h3>
<p>I want to keep this tutorial simple, without unnecessary details and additional functions. Therefore, let&rsquo;s create some artificial data with different characteristics and assign labels 0, 1, and 2.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">0.3</span><span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span>  <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>To make things a bit harder for the algorithm, I have added some slight random noise to functions (line 2,3,4) so that it won&rsquo;t be 100% aligned with the perfect sinusoid equation.</p>
<p>Once we have done that, we can utilize our function for building lagged time series to prepare time slices for each process. We will use K = 10 lags here (9 lags + so-called lag-0: the &ldquo;current&rdquo; time).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">NLAGS</span> <span class="o">=</span> <span class="mi">9</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_y1</span> <span class="o">=</span> <span class="n">generate_lagged_data</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y1</span><span class="p">),</span> <span class="n">NLAGS</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_y1</span><span class="p">[</span><span class="s1">&#39;cls&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_y2</span> <span class="o">=</span> <span class="n">generate_lagged_data</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y2</span><span class="p">),</span> <span class="n">NLAGS</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_y2</span><span class="p">[</span><span class="s1">&#39;cls&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_y3</span> <span class="o">=</span> <span class="n">generate_lagged_data</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y3</span><span class="p">),</span> <span class="n">NLAGS</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">lagged_y3</span><span class="p">[</span><span class="s1">&#39;cls&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="n">all_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">lagged_y1</span><span class="p">,</span> <span class="n">lagged_y2</span><span class="p">,</span> <span class="n">lagged_y3</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>The data is presented on chart below. Double-click a legend to isolate a single time series. You can also zoom in and slice it.</p>


<div id="chart-915248736" class="chart"></div>
<script>
  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === 'undefined' ) {
        return;
      }
      clearInterval( a );

      Plotly.d3.json("./sinusoids.json", function(chart) {
        Plotly.plot('chart-915248736', chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
</script>
<h3 id="the-experiment">The experiment</h3>
<p>We will keep the last 20% of the data samples as a test set, and the remaining will be mixed up together and used during training.</p>
<p>We will normalize the training data and use normalizer trained on it to do the same with test data. Similar things can be achieved by building a pipeline (combining an LSTM with Scaler), but let&rsquo;s keep things simple here.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">build_train_test_data</span><span class="p">(</span><span class="n">series</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span> <span class="n">test_perc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Builds a train-test dataset using a time-split method. 
</span></span></span><span class="line"><span class="cl"><span class="s2">    We will keep last test_prec of each time series as a test set, training on the remaining data.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">series</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">test_nobs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">test_perc</span> <span class="o">*</span> <span class="n">ts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">ts_train</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span><span class="n">test_nobs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">ts_test</span> <span class="o">=</span> <span class="n">ts</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="n">test_nobs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train_data</span><span class="p">,</span> <span class="n">ts_train</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">test_data</span><span class="p">,</span> <span class="n">ts_test</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">build_train_test_data</span><span class="p">([</span><span class="n">lagged_y1</span><span class="p">,</span> <span class="n">lagged_y2</span><span class="p">,</span> <span class="n">lagged_y3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;cls&#39;</span><span class="p">),</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;cls&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">cls</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_train_ohe</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_test_ohe</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>We can take a look on a single sample in X_train. This is just a part of some sinusoid, a slice of the curve.</p>


<div id="chart-412956783" class="chart"></div>
<script>
  (function() {
    let a = setInterval( function() {
      if ( typeof window.Plotly === 'undefined' ) {
        return;
      }
      clearInterval( a );

      Plotly.d3.json("./slice.json", function(chart) {
        Plotly.plot('chart-412956783', chart.data, chart.layout, {responsive: true});
      });
    }, 500 );
  })();
</script>
<p>Now it&rsquo;s time to conduct our experiment. As a baseline to compare with, we will use random guessing with prior probability :) We would expect our model to be better than that. The architecture for this LSTM has been arbitrarily chosen - it&rsquo;s not the main point of this exercise, so repeated cross-validation or using Keras Tuner for finding the best hyperparameters is beyond the scope of this post.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">build_model</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">krs</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Builds a Keras model. A wrapper function for SciKeras.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">inp</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">NLAGS</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">32</span><span class="p">)(</span><span class="n">inp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dense1</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">lstm_out</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dense2</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">dense1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">out</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">dense2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">krs</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">krs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Precision</span><span class="p">(),</span> <span class="n">krs</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Recall</span><span class="p">()])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model_wrapper</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;stratified&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">f1</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model_cv</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model_wrapper</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_ohe</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">f1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dummy_cv</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_ohe</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">f1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cv_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;LSTM&#39;</span><span class="p">:</span> <span class="n">model_cv</span><span class="p">,</span> <span class="s1">&#39;Dummy&#39;</span><span class="p">:</span> <span class="n">dummy_cv</span><span class="p">})</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>In the experiment, the following things happened:</p>
<ul>
<li><strong>Lines 1-12</strong>: Wrap model building into function so it can be later used by Scikit-learn API.</li>
<li><strong>Line 14</strong>: Use <a href="https://www.adriangb.com/scikeras/stable/quickstart.html#training-a-model" target="_blank" rel="noopener">Scikeras</a> API to make Keras model usable within cross-validation</li>
<li><strong>Line 15</strong>: Prepare a dummy classifier that randomly predicts classes based on their prior probability.</li>
<li><strong>Line 16</strong>: Prepare a model metric for comparison: micro-averaged F1 score.</li>
<li><strong>Line 17-19</strong>: Perform repeated stratified K-fold cross-validation on each model using the metric provided.</li>
<li><strong>Line 20</strong>: Save all metrics in a one data frame for later comparison</li>
</ul>
<p>The model is trained, so let&rsquo;s evaluate it on the test set. And use a non-parametric statistical test to compare the statistical significance of the results against a random baseline.</p>
<p>To compare results, we will utilize the non-parametric Wilcoxon signed-rank test. Non-parametric tests are recommended every time; we cannot guarantee that strict assumptions, e.g., normality of errors, heteroskedasticity, independence of samples, etc., are not violated [<a href="#salzberg">Salzberg 1997</a> ;<a href="#desmar">DemÅ¡ar, 2006</a>]. Our null hypothesis is that there is no difference between the two classifiers. An alternative hypothesis is that the difference is present in favor of an LSTM. We will conduct a test on a significance level alpha = 0.05 (meaning that we accept only a 5% chance that observed results are accidental).</p>
<p>Checking the model on test data:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_ohe</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">yhat_lstm</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat_lstm</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<pre><code>          precision    recall  f1-score   support

       0       0.85      0.86      0.85       198
       1       0.91      0.83      0.87       198
       2       0.89      0.95      0.92       198

accuracy                           0.88       594
macro avg      0.88      0.88      0.88       594
weighted avg   0.88      0.88      0.88       594
</code></pre>
<p>Statistical comparison of cross val scores:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cv_scores</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&#34;Results comparison&#34;</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="png" srcset="
               /en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_34_0_hu0452a36f962bf7cfff31bdef7325aa26_6097_51e4279f3a7be72893ba3a3b7c853030.webp 400w,
               /en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_34_0_hu0452a36f962bf7cfff31bdef7325aa26_6097_72f7e2a37822ee0bfa168ef05818fc9f.webp 760w,
               /en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_34_0_hu0452a36f962bf7cfff31bdef7325aa26_6097_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_34_0_hu0452a36f962bf7cfff31bdef7325aa26_6097_51e4279f3a7be72893ba3a3b7c853030.webp"
               width="372"
               height="264"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">st</span><span class="o">.</span><span class="n">wilcoxon</span><span class="p">(</span><span class="n">model_cv</span><span class="p">,</span> <span class="n">dummy_cv</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<pre><code>WilcoxonResult(statistic=55.0, pvalue=0.0009765625)
</code></pre>
<p>As we can see by a naked eye: the LSTM model outperformed random choice significantly. Our statistical test allows us to reject the null hypothesis :)</p>
<h3 id="wrong-approach">Wrong approach</h3>
<p>You might wonder - &ldquo;ok, but what will happen if I ignore the time dependence and just sample points at random from each process. This is an easy task - each curve is a sinusoid with a characteristic morphology - if we sample enough data points, it should be sufficient to recognize a typical range of values for each type&rdquo;. Here we treat each data point as an iid datum - independent from others but from the same characteristic distribution, specific for each class. So we will turn the whole exercise into a typical classification problem from tabular data.</p>
<p>We might ignore for a while the fact that this is the fundamentally wrong approach because the problem IS a time series classification and check if it&rsquo;s going to work after all. Let&rsquo;s try: we skip the lagging part entirely and randomly sample data points for each class. To make it easier for the algorithm: we will sample with a replacement for each time series so that the algorithm may see the same data points twice: in training and testing. It should be easy, shouldn&rsquo;t it? We will use one of the Gradient Boosting family models to model such data.</p>
<p>Data samples without time dependence preparation:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_iid_data</span><span class="p">(</span><span class="n">ts</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">nsamp</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Generates random samples with replacement, assuming that the data is IID. It does not preserve
</span></span></span><span class="line"><span class="cl"><span class="s2">    a time dependence and samples each data point multiple times.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">rnd_features</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">rnd_feature</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">nsamp</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">rnd_features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;f_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rnd_feature</span>
</span></span><span class="line"><span class="cl">    <span class="n">rnd_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rnd_features</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rnd_df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">rnd_df</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rnd_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ts</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">y3</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span> <span class="o">=</span> <span class="n">generate_iid_data</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">NLAGS</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">800</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rnd_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rnd_data</span><span class="p">,</span> <span class="n">df</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rnd_data</span><span class="o">.</span><span class="n">shape</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>The experiment:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">X_rnd</span><span class="p">,</span> <span class="n">y_rnd</span> <span class="o">=</span> <span class="n">rnd_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">),</span> <span class="n">rnd_data</span><span class="o">.</span><span class="n">y</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train_rnd</span><span class="p">,</span> <span class="n">X_test_rnd</span><span class="p">,</span> <span class="n">y_train_rnd</span><span class="p">,</span> <span class="n">y_test_rnd</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_rnd</span><span class="p">,</span> <span class="n">y_rnd</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">xgb_rnd_cv</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">X_train_rnd</span><span class="p">,</span> <span class="n">y_train_rnd</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">f1</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>Collecting the cv scores and comparison:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">cv_scores</span><span class="p">[</span><span class="s1">&#39;xgboost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">xgb_rnd_cv</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cv_scores</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="png" srcset="
               /en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_48_1_hu6ea9f90bd386a09d5eda4c1014740044_5415_3cde6e58f0a91b35c9452026c6bb929e.webp 400w,
               /en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_48_1_hu6ea9f90bd386a09d5eda4c1014740044_5415_fb73ee9835a83b843b8d665dd3ea2b11.webp 760w,
               /en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_48_1_hu6ea9f90bd386a09d5eda4c1014740044_5415_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/en/post/rnns/fifty-shapes-of-time/classification_from_curve_morphology_48_1_hu6ea9f90bd386a09d5eda4c1014740044_5415_3cde6e58f0a91b35c9452026c6bb929e.webp"
               width="372"
               height="248"
               loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>XGboost prediction on test data:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">xgb_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_rnd</span><span class="p">,</span> <span class="n">y_train_rnd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">yhat_xgb</span> <span class="o">=</span> <span class="n">xgb_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_rnd</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_rnd</span><span class="p">,</span> <span class="n">yhat_xgb</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div>
<pre><code>            precision    recall  f1-score   support

          0       0.61      0.81      0.70       149
          1       0.54      0.51      0.52       158
          2       0.54      0.42      0.47       173

  accuracy                           0.57       480
  macro avg      0.57     0.58       0.57       480
  weighted avg   0.56     0.57       0.56       480
</code></pre>
<p>As we can see, such a classifier performs much worse than our previous model. Clearly, it possesses SOME skill - points that belong to common distribution shuffled at random definitely share some properties, but it is not enough to achieve satisfactory results.</p>
<p>For the sake of completeness and reliability, let&rsquo;s perform a non-parametric equivalent of ANOVA: a Friedman chi-square test, suitable for comparing multiple algorithms on multiple datasets [<a href="#desmar">DemÅ¡ar, 2006</a>]. Our null hypothesis is that there is no significant difference between models. An alternative hypothesis: is that such a difference exists. Suppose we manage to reject the null hypothesis. In that case, we will perform a pairwise, post-hoc non-parametric test to detect differences between pairs of classifiers with corrected p-value to control the false discovery rate [<a href="#trawinski">Trawinski et al. 2012</a>].</p>
<p>Overall Friedmann test:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pg</span><span class="o">.</span><span class="n">friedman</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cv_scores</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Source</th>
      <th>W</th>
      <th>ddof1</th>
      <th>Q</th>
      <th>p-unc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Friedman</th>
      <td>Within</td>
      <td>1.0</td>
      <td>2</td>
      <td>20.0</td>
      <td>0.000045</td>
    </tr>
  </tbody>
</table>
</div>
<p>Pairwise comparison</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pg</span><span class="o">.</span><span class="n">pairwise_ttests</span><span class="p">(</span><span class="n">cv_scores</span><span class="o">.</span><span class="n">melt</span><span class="p">(),</span> <span class="n">between</span><span class="o">=</span><span class="s1">&#39;variable&#39;</span><span class="p">,</span> <span class="n">dv</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="n">parametric</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
    horizontal-align: center;
}

.dataframe thead th {
    text-align: center;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Contrast</th>
      <th>A</th>
      <th>B</th>
      <th>Paired</th>
      <th>Parametric</th>
      <th>U-val</th>
      <th>alternative</th>
      <th>p-unc</th>
      <th>hedges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>variable</td>
      <td>Dummy</td>
      <td>LSTM</td>
      <td>False</td>
      <td>False</td>
      <td>0.0</td>
      <td>two-sided</td>
      <td>0.00018</td>
      <td>-8.47105</td>
    </tr>
    <tr>
      <th>1</th>
      <td>variable</td>
      <td>Dummy</td>
      <td>xgboost</td>
      <td>False</td>
      <td>False</td>
      <td>0.0</td>
      <td>two-sided</td>
      <td>0.00017</td>
      <td>-10.01235</td>
    </tr>
    <tr>
      <th>2</th>
      <td>variable</td>
      <td>LSTM</td>
      <td>xgboost</td>
      <td>False</td>
      <td>False</td>
      <td>100.0</td>
      <td>two-sided</td>
      <td>0.00018</td>
      <td>3.56603</td>
    </tr>
  </tbody>
</table>
</div>
<p>And again, there are no surprises here. We can safely reject the null hypothesis and (after pairwise testing) see clearly, that LSTM, preserving time-dependence, performs much better than XGBoots, even after aggressive resampling with replacement.</p>
<h2 id="summary">Summary</h2>
<p>The points below briefly summarize what has been discussed in this blogpost:</p>
<ol>
<li>LSTM requires data in a format: N samples x T time steps x F features.</li>
<li>For univariate time series, F = 1, so the data shape becomes N x T x 1
Such a structure can be generated from data by subsequent shifting the time series.</li>
<li>A predictive model that preserves the time-dependence performs much better than random sampling, which treats the data as iid. This is a fundamentally wrong approach for such problems.</li>
</ol>
<h2 id="bibliography">Bibliography</h2>
<ol>
<li>
<p id='cs230'>CS 230 - Recurrent Neural Networks Cheatsheet; https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks</p>
</li>
<li>
<p id='desmar'>DemÅ¡ar, J. (2006) â€œStatistical comparisons of classifiers over multiple data setsâ€, Journal of Machine learning research, nr 7(Jan), ss. 1â€“30</p>
</li>
<li>
<p id='mikolov'>Exploding & vanishing problem: Pascanu, R., Mikolov, T., & Bengio, Y. (2013, May). On the difficulty of training recurrent neural networks. In International conference on machine learning (pp. 1310-1318). PMLR. https://arxiv.org/pdf/1211.5063.pdf</p>
</li>
<li>
<p id='handbook'>NIST/SEMATECH e-Handbook of Statistical Methods, https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc41.htm, 29.04.2022</p>
</li>
<li>
<p id='karpathy'> Reasonable choices: Blog, Karpathy A. (2015). The Unreasonable Effectiveness of Recurrent Neural Networks. URL: http://karpathy. github.io/2015/05/21/rnn-effectiveness/dated May 21, 33. </p>
</li>
<li>
<p id='salzberg'>Salzberg, S. L. (1997) â€œOn comparing classifiers: Pitfalls to avoid and a recommended approachâ€, Data mining and knowledge discovery. Springer, nr 1(3), ss. 317â€“328</p>
</li>
<li>
<p id='trawinski'>Trawinski, B. et al. (2012) â€œNonparametric statistical analysis for multiple comparison of machine learning regression algorithmsâ€, International Journal of Applied Mathematics and Computer Science, nr 22(4), ss. 867â€“881. doi: 10.2478/v10006-012-0064-z</p></li>
</ol>

          </div>

          

<div class="article-tags">
  
  <a class="badge badge-light" href="/en/tag/deep-learning/">deep learning</a>
  
  <a class="badge badge-light" href="/en/tag/time-series/">Time-series</a>
  
  <a class="badge badge-light" href="/en/tag/rnn/">RNN</a>
  
</div>



          
          
          <div class="article-widget">
            
<div class="post-nav">
  
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on May 16, 2022</p>

          



          




          


        </div>

      </article>

      <footer class="site-footer">

  



  

  

  

  
  






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    Â© 2022 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> â€” the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>


    </main>
  </div>
</div>

  </div>

  <div class="page-footer">
    
    
  </div>

      

    
    <script src="/js/vendor-bundle.min.92d2024afaa4dce0cad42ba360879ce9.js"></script>

    
    
    
      

      
      

      
        
        <script src="https://cdn.jsdelivr.net/gh/mermaid-js/mermaid@v8.8.4/dist/mermaid.min.js" integrity="sha512-+TNmhaRJf3jyYHTpzEq/5I6b+aGyhzWb21mGdHAjxSGSYwxN9Grug3Y3B9qVxWfKKY8MscE/6mr9walWvFLFvQ==" crossorigin="anonymous" title="mermaid"></script>
      

    

    
    
    

    
    
    <script src="https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js" integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    
      <script src="https://cdn.jsdelivr.net/gh/plotly/plotly.js@v1.55.2/dist/plotly.min.js" integrity="sha512-gttPT9uTUiaLBj6XZdcB0ydKXiDaBwstInkN4Qvp1Nz3iwXNc8TTQplIEPIGxyJBDqERjwkKxf2OyO47/0EHbQ==" crossorigin="anonymous"></script>
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    

    
    
    
    <script id="page-data" type="application/json">{"use_headroom":false}</script>

    
    
    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.e930dd1bcd2253a870f7127b92051548.js"></script>

    
    
    
    
    
    
      
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>






</body>
</html>
