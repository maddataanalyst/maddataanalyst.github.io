<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP | NeuraSYS</title>
    <link>https://maddataanalyst.github.io/pl/tag/nlp/</link>
      <atom:link href="https://maddataanalyst.github.io/pl/tag/nlp/index.xml" rel="self" type="application/rss+xml" />
    <description>NLP</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>pl</language><lastBuildDate>Fri, 14 Apr 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://maddataanalyst.github.io/media/icon_hu5b489458e36ca6f814edb4aedf2e84e5_21223_512x512_fill_lanczos_center_3.png</url>
      <title>NLP</title>
      <link>https://maddataanalyst.github.io/pl/tag/nlp/</link>
    </image>
    
    <item>
      <title>ChatGPT mnie okłamał! - czyli o tym, jak nie oceniać modeli językowych</title>
      <link>https://maddataanalyst.github.io/pl/post/rozne/chat_gpt_klamie/</link>
      <pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/post/rozne/chat_gpt_klamie/</guid>
      <description>&lt;h2 id=&#34;wstęp&#34;&gt;Wstęp&lt;/h2&gt;
&lt;p&gt;Wyobraźnię wielu osób rozbudza w ostatnim czasie ChatGPT: cudowne dzieło firmy OpenAI, demonstrujące niesamowite umiejętności rozumienia języka naturalnego i przetwarzania informacji. Internet co chwila obiegają wieści, o zaskakujących i błyskotliwych odpowiedziach, a także o  zdolnościach pisania kodu.&lt;/p&gt;
&lt;p&gt;Jednocześnie słyszy się też o błędach popełnionych przez ChatGPT, konstruowanych “fałszywych oskarżeniach” pod adresem różnych osób (&lt;a href=&#34;https://www.bbc.com/news/technology-65202597&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;przykład sprawy burmistrza z Autstralii&lt;/a&gt;), oraz idiotyzmach i nielogicznościach jego wypowiedzi.&lt;/p&gt;
&lt;p&gt;Z zaskoczeniem obserwuję co najmniej trzy postawy w stosunku do Chatu GPT:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Traktowanie go jako “mądrzejszej wyszukiwarki” Google&lt;/strong&gt; - część osób reprezentujących ten pogląd uważa, że ChatGPT jest po prostu &amp;ldquo;językowym opakowaniem&amp;rdquo; na wyszukiwarkę treści;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hurraoptymizm&lt;/strong&gt; i przekonanie, że mamy do czynienia z &amp;ldquo;prawdziwym AI&amp;rdquo;, które zrewolucjonizuje każdy element życia - takie podejście przeważa wśród technologicznych entuzjastów, korporacyjnych managerów i niektórych osób zainteresowanych &amp;ldquo;AI&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Silny sceptycyzm lub wręcz strach przed utratą pracy&lt;/strong&gt; i zastąpieniem przez nowy wynalazek - takie głosy dochodzą m.in. z grona programistów, obserwujących możliwości Chatu GPT, modelu CODEX, czy Github Copilot-a.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Wiele osób, zupełnie nie zdaje sobie sprawy, czym tak naprawdę jest ChatGPT i pokrewne rozwiązania. Co za tym idzie: dlaczego działają tak, jak działają i dlaczego się mylą. Spróbujmy odpowiedzieć na to pytanie.&lt;/p&gt;
&lt;h2 id=&#34;uczenie-maszynowe&#34;&gt;Uczenie maszynowe&lt;/h2&gt;
&lt;p&gt;ChatGPT należy do bardzo szerokiego grona dużych modeli językowych (ang. LLM - &lt;strong&gt;large language models&lt;/strong&gt;), algorytmów uczenia maszynowego (ML - ang. &lt;strong&gt;machine learning&lt;/strong&gt; znanych od dawna i stanowiących jedna z poddziedzin badań nad sztuczną inteligencją. Powstało wiele definicji tego zagadnienia, myślę, że możemy w tym miejscu przytoczyć dwie.&lt;/p&gt;
&lt;p&gt;Pierwszą z nich jest określenie terminu “uczenie się”, sformułowane przez Herberta Simona - laureata nagrody Nobla w dziedzinie ekonomii, jednego z pionierów badań nad SI.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Uczenie się oznacza takie zmiany adaptacyjne w systemie, iż jest on w stanie lepiej wykonać w przyszłości takie same zadania lub zadania należące do tej samej kategorii.
Simon, H. A. (1983). Why should machines learn?. W &lt;em&gt;Machine learning&lt;/em&gt;  (pp. 25-37). Morgan Kaufmann.
(tł. własne)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Drugą definicją jest ta sformułowana przez wybitnego polskiego naukowca, autora znakomitej książki “Systemy Uczące się”, Pawła Cichosza:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Uczeniem się systemu jest każda autonomiczna zmiana w systemie zachodząca na podstawie
doświadczeń, która prowadzi do poprawy jakości jego działania.
Cichosz, P. (2007) Systemy uczące się. Wyd. 2. Warszawa: Wydawnictwa Naukowo-Techniczne&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;W obu tych definicjach widzimy łączące je, ważne punkty:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Stopniowe nabywanie doświadczenia&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wykorzystywanie tego doświadczenia&lt;/strong&gt;, do stopniowej poprawy działania systemu.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomiczny charakter zmian&lt;/strong&gt; - to oznacza, że system sam reguluje sposób wykorzystania zgromadzonej wiedzy i nie wymaga przeprogramowywania przez człowieka.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tak, w ogromnym skrócie, wygląda działanie większości systemów uczenia maszynowego. Wiele z nich, w tym modele językowe, uczymy w sposób bardzo podobny do tego, jak uczą się ludzie:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pokazujemy przykładowe dane (pytania), wraz z odpowiedziami.&lt;/li&gt;
&lt;li&gt;Pozwalamy algorytmowi przedstawić własne odpowiedzi.&lt;/li&gt;
&lt;li&gt;Weryfikujemy wynik z “kluczem” (poprawnymi odpowiedziami), dając sygnał zwrotny: “dobrze/źle”, dzięki czemu system koryguje swoje zachowanie.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph LR
	pytania[pytania lub materiał] --przekazanie--&gt; algorytm
	popr[poprawne odpowiedzi] --&gt; weryfikacja
	subgraph uczenie
		algorytm
		odp[proponowane odpowiedzi]
		weryfikacja
		algorytm --udziela--&gt; 	odp --&gt; weryfikacja
		weryfikacja --sygnał błędu i poprawa--&gt; algorytm
	end
&lt;/div&gt;
&lt;p&gt;Pokazany wyżej proces nosi nazwę “uczenia nadzorowanego” i jest jednym z wielu sposobów szkolenia modeli ML.&lt;/p&gt;
&lt;h2 id=&#34;modele-językowe&#34;&gt;Modele językowe&lt;/h2&gt;
&lt;p&gt;Modele językowe, do których należy ChatGPT, Bard i podobne wpisują się w opisany schemat. W ich przypadku, uczenie polega na pokazywaniu zdań z języka naturalnego, wraz z ich kontekstem i np. kategorią tematyczną, do której należą. Algorytm uczy się, jakie sekwencje słów, zdań, akapitów i paragrafów, opisują dane zagadnienia. Podział na pytania/materiał do nauki i proponowane odpowiedzi może w tym przypadku wyglądać następująco:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Zadanie&lt;/th&gt;
&lt;th&gt;Pytanie&lt;/th&gt;
&lt;th&gt;Poprawne odpowiedzi&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Jakie powinno być następne słowo?&lt;/td&gt;
&lt;td&gt;Ala ma&lt;/td&gt;
&lt;td&gt;kota&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Bitwa pod Grunwaldem rozegrała się w&lt;/td&gt;
&lt;td&gt;1410 roku&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1410 r.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AD 1410&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Do jakiej kategorii należy zdanie?&lt;/td&gt;
&lt;td&gt;Na giełdzie zapanowały ponure nastroje, kursy akcji lecą w dół.&lt;/td&gt;
&lt;td&gt;Ekonomia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Finanse&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Giełda&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Prezydent wygłosił wspaniałe przemówienie, które wzmocni jego pozycję w nadchodzących wyborach.&lt;/td&gt;
&lt;td&gt;Polityka&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Publicystyka&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Odpowiedz na pytanie pełnym zdaniem.&lt;/td&gt;
&lt;td&gt;Ile kół ma typowy samochód?&lt;/td&gt;
&lt;td&gt;Typowy samochód ma 4 koła.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Samochód ma cztery koła.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Auta mają po 4 koła.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Jak widać, wiele pytań/zadań ma więcej niż jedną poprawną odpowiedź. Zazwyczaj można ją sformułować na kilka sposobów, w danym języku. Zdarza się też, że treści mogą być wzajemnie sprzeczne (&lt;em&gt;Ala ma kota, Ala ma bzika, Ala ma fioła&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Co bardzo ważne - ChatGPT i inne modele z jego rodziny &lt;strong&gt;uczą się operowania językiem naturalnym&lt;/strong&gt; przez analizę wielu zdań i wypowiedzi. Tymczasem wiele postów/komentarzy i opinii jest wzajemnie sprzecznych, zwłaszcza gdy Internauci wyrażają w nich swoje opinie. Zadaniem LLM-ów jest formułować wypowiedzi na piśmie, podobnie jak robi to człowiek przy klawiaturze, &lt;strong&gt;nie są natomiast encyklopediami ani bazą wiedzy symbolicznej&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Gdy zaglądasz do encyklopedii, szukasz zazwyczaj po indeksie (np. litera “u” → uczenie maszynowe) lub w danej kategorii (np. kategoria nauki ścisłe → litera “u” → uczenie maszynowe).&lt;/p&gt;
&lt;p&gt;Modele językowe są uczone na kategoriach zdań, owszem (np. zdania z zakresu polityki lub ekonomii), ale ich zadaniem jest formułowanie płynnych wypowiedzi na dany temat, a nie poszukiwania encyklopedyczne (z małymi wyjątkami, patrz niżej 🙂).&lt;/p&gt;
&lt;p&gt;W jaki sposób te modele mogą rozumieć język pisany? Istnieje wiele sposobów szkolenia, ale jednym z nich są tzw. mechanizmy uwagi, stanowiące podwaliny architektury o znajomo brzmiącej nazwie “Transformery”.&lt;/p&gt;
&lt;h2 id=&#34;mechanizm-uwagi-i-transformery&#34;&gt;Mechanizm uwagi i transformery&lt;/h2&gt;
&lt;p&gt;Człowiek posługujący się dowolnym językiem, zapoznając się z wypowiedzią, buduje w swojej głowie “drzewo zależności” - co zdanie opisuje, w jakim czasie, co jest podmiotem, a co orzeczeniem. Każdy język rządzi się swoimi prawami, język angielski i pokrewne mają co prawda pod pewnymi względami przewagę (ograniczona odmiana słów w porównaniu np. do języka polskiego), ale zasada działania jest bardzo podobna.&lt;/p&gt;
&lt;p&gt;Spójrz na poniższe zdanie:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Kobieta usiadła na ławce i rozglądała się po parku.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Kto usiadł? &lt;em&gt;Kobieta.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Na czym usiadła? &lt;strong&gt;Na ławce&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Kto się rozglądał - kobieta, czy ławka? &lt;strong&gt;Kobieta&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Dla osoby znającej język polski takie zależności są oczywiste. Obcokrajowcy, oraz systemy językowe jak ChatGPT muszą je poznać. Ludzie uczą się na kursach gramatyki, czasów, stron i trybów, robiąc ćwiczenia i rozmawiając z lektorami.&lt;/p&gt;
&lt;p&gt;ChatGPT i modele językowe przerabiają miliony podobnych przykładów, dostając informację zwrotną, czy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Prawidłowo rozpoznały kontekst;&lt;/li&gt;
&lt;li&gt;Wygenerowane przez nie wypowiedzi są podobne do używanych w danym języku.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Mechanizm uwagi (ang. &lt;strong&gt;attention&lt;/strong&gt; nazywany też przez mechanizmem atencji pozwala algorytmom brać pod uwagę dotychczasowy kontekst zdania i wpływ poszczególnych jego części na to, co ma być dalej (następne słowo lub zdanie), lub na analizę tematu/zagadnienia (klasyfikacja).&lt;/p&gt;
&lt;p&gt;Mechanizmy uwagi w sztucznych sieciach neuronowych pełnią zbliżoną rolę do pól recepcyjnych i “uwagi konkurencyjnej” w organizmach biologicznych - skupiają system na wybranym kawałku otoczenia, pozwalając analizować kontekst zachodzących zdarzeń.&lt;/p&gt;
&lt;p&gt;Diagram poniżej pokazuje bardzo uproszczony mechanizm działania uwagi dla przykładowego zdania. Gwiazdki wskazują podmiot zdania: jest nim &lt;em&gt;kobieta&lt;/em&gt; i niewątpliwie dalsze elementy zdania będą odnosić się do niej, jako głównej “bohaterki”.&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph
	subgraph zdanie
	  s1[słowo 1: *Kobieta*] --&gt; s2[słowo 2: usiadła] --&gt; s3[słowo 3: na] --&gt; s4[słowo 4: ławce] --???--&gt; s5[słowo 5: ?]
	end
	subgraph reprezentacja
		s1 --&gt; sym1[*symbol1*]
		s2 --&gt; sym2[symbol2]
		s3 --&gt; sym3[symbol3]
		s4 --&gt; sym4[symbol4]
		sym1 --&gt; sym2 --&gt; sym3 --&gt; sym4
	end
	subgraph &#34; &#34;
		sym1 --*waga1*--&gt;oc
		sym2 --waga2--&gt;oc
		sym3 --waga3--&gt;oc
		sym4 --waga4--&gt;oc
		oc[ocena kontekstu] --predykcja--&gt; s5
	end
&lt;/div&gt;
&lt;p&gt;Wiele zagnieżdżonych mechanizmów uwagi, działających wspólnie z dodatkowymi fragmentami sieci składają się na architekturę zwaną “Transformerem”, która pozwala przetwarzać nawet bardzo długie sekwencje.&lt;/p&gt;
&lt;p&gt;Warto pamiętać też, że algorytmy uczenia maszynowego nie przetwarzają języka bezpośrednio - słowa są zmieniane na reprezentację numeryczną w mechanizmie zwanym “osadzaniem” (ang. &lt;strong&gt;embedding&lt;/strong&gt;) - który pozwala przedstawiać słowa jako wektory liczb. W procesie uczenia następuje szereg operacji probabilistycznych i matematycznych, mających odzwierciedlić uczone treści. Jeśli wszystko idzie zgodnie z planem, pojęcia bliskoznaczne znajdują się wówczas niedaleko siebie na płaszczyźnie numerycznej. Dodatkowo, możliwe są na nich operacje arytmetyczne, prowadzące do zaskakująco trafnych przekształceń jak np:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;król - mężczyzna  + kobieta ~ królowa&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Przykład umiejscowienia słów jako reprezentacji numerycznych znajduje się poniżej:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;word_transforms&#34; srcset=&#34;
               /pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_85b1c5b99387c35f1ccebfbf78af2673.webp 400w,
               /pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_bb1d28375b6638e7b81dc2d7a4483673.webp 760w,
               /pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://maddataanalyst.github.io/pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_85b1c5b99387c35f1ccebfbf78af2673.webp&#34;
               width=&#34;532&#34;
               height=&#34;192&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Jakiś czas temu, miałem przyjemność opowiadać podczas konferencji Data Science Summit o dokładnym mechanizmie wykorzystania osadzeń/embedding’ów w zadaniach klasyfikacji, lub rekomendacji. Materiały z wykładu znajdziesz &lt;a href=&#34;https://filip-wojcik.com/uploads/embeddings_other_than_nlp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutaj&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ChatGPT został nauczony na ogromnych zbiorach tekstów z sieci (m. in. &lt;a href=&#34;https://paperswithcode.com/dataset/bookcorpus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BooksCorpus&lt;/a&gt;, &lt;a href=&#34;https://www.eleuther.ai/projects/owt2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebText2&lt;/a&gt;) oraz tzw. &lt;a href=&#34;https://commoncrawl.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Common Crawl&lt;/a&gt;. Jest to zbiór danych składający się z miliardów stron internetowych, które są regularnie przeszukiwane i indeksowane przez roboty Google i innych podobnych firm. OpenAI, organizacja odpowiedzialna za stworzenie ChatGPT, wykorzystała wersję z 2019 roku tego zbioru, która składała się z ponad 40 terabajtów danych tekstowych. Zbiór zawierał wiele różnych typów tekstów, w tym artykuły, recenzje, wpisy na blogach, a nawet fora internetowe.&lt;/p&gt;
&lt;p&gt;Co ważne: wiele tekstów i wypowiedzi krążących w Internecie jest wzajemnie sprzeczna. Ludzie podają nieprawdziwe informacje, odpowiadają nie na temat, tworzą teorie spiskowe…. Wszystko to, wraz z kontekstem wypowiedzi stało się materiałem uczącym dla LLM.&lt;/p&gt;
&lt;h2 id=&#34;chodząca-encyklopedia&#34;&gt;Chodząca encyklopedia?&lt;/h2&gt;
&lt;p&gt;Powyższy, mocno uproszczony opis, powinien dać nam pewien ogląd czym są i jak działają algorytmy pokrewne do ChatuGPT. W najprostszym ujęciu, są to modele uczenia maszynowego, bazujące na wielu przykładach, jakie im przedstawiono, nauczone generowania nowych wypowiedzi, będących odpowiedziami na konkretne pytania, lub w sposób swobodny.&lt;/p&gt;
&lt;p&gt;Swoje teksty konstruują za każdym razem od nowa, kierując się mechanizmami kontekstu i uwagi, pozwalającymi na rozpoznanie tematu “dyskusji”, dotąd wypowiedzianych kwestii itd. W tym procesie starają się upodobnić własne dzieła do tych, które były im przedstawione jako charakterystyczne dla danego języka.&lt;/p&gt;
&lt;p&gt;W tym kontekście, ChatGPT i modele LLM &lt;strong&gt;nie mogą być&lt;/strong&gt; uznawane za “chodzące encyklopedie”, albo wyszukiwarki treści. Nie posiadają ustrukturyzowanej wiedzy encyklopedycznej, nie są uwarunkowane na udzielanie &amp;ldquo;poprawnych odpowiedzi&amp;rdquo; - generują słowa, które mają być spójne z językiem, w jakim prowadzona jest konwersacja, kontekstem rozmowy, jej tematem, itp. Z tego względu, mogą mijać się z prawdą.&lt;/p&gt;
&lt;p&gt;W chwili pisania tego tekstu, powstają już wtyczki i rozszerzenia, pozwalające modelom LLM łączyć się z bazami wiedzy, posługiwać się wyszukiwarkami treści, albo narzędziami matematycznymi takimi jak Wolfram Alpha do wykonywania &lt;strong&gt;celowo poprawnych obliczeń&lt;/strong&gt; lub wyszukiwania encyklpedycznych informacji.&lt;/p&gt;
&lt;p&gt;Nie zmienia to jednak faktu, że w swoim jądrze modele LLM są modelami &lt;strong&gt;językowymi&lt;/strong&gt; a nie chodzącymi encyklopediami. Z tego względu “oskarżanie” ich o popełnienie błędu albo generowanie nieprawidłowych treści jest zupełnym niezrozumieniem przeznaczenia tych narzędzi.&lt;/p&gt;
&lt;h2 id=&#34;sztuczne-języki&#34;&gt;Sztuczne języki&lt;/h2&gt;
&lt;p&gt;Mając na uwadze powyższy opis, można sobie zadać pytanie: dlaczego ChatGPT tak dobrze programuje i pisze kod relatywnie sprawnie?&lt;/p&gt;
&lt;p&gt;Słowo “język” w odniesieniu do dialektów programistycznych jest uzasadnione. Języki programowania to symboliczne, sztuczne języki, o charakterze utylitarnym, czyli służącym konkretnemu celowi - tworzeniu działających aplikacji i algorytmów w sposób imperatywny, czyli jednoznacznie wskazujący na operacje do wykonania.&lt;/p&gt;
&lt;p&gt;W przeciwieństwie do ludzkich języków, języki programowania:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;są dużo bardziej &lt;strong&gt;jednoznaczne&lt;/strong&gt;, pozbawione zbędnych “ozdobników” ;&lt;/li&gt;
&lt;li&gt;mają &lt;strong&gt;ściśle określoną składnię.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Dodatkowo: kod udostępniony publicznie w Internecie bardzo często jest napisany poprawnie i działa.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Jeśli dodamy do siebie powyższe trzy punkty:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;jednoznaczność + czytelny, sformalizowany język + dużo poprawnych i prawidłowych przykładów&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;otrzymujemy &lt;strong&gt;znakomity zestaw wypowiedzi uczących dla LLM&lt;/strong&gt;. W przeciwieństwie do forów, blogów i komentarzy, gdzie każdy wyraża swoje opinie - “wypowiedzi” pisane w językach programowania są dużo bardziej zwarte, poprawne i jednoznaczne.&lt;/p&gt;
&lt;h2 id=&#34;co-dalej&#34;&gt;Co dalej?&lt;/h2&gt;
&lt;p&gt;Niewątpliwie ChatGPT i pokrewne modele LLM stanową rewolucję w dziedzinie praktycznych zastosowań AI. Pozwolą na automatyzację wielu zadań, generowanie treści, do tej pory zarezerwowanych dla ludzkich twórców, w tym także kodu źródłowego aplikacji.&lt;/p&gt;
&lt;p&gt;Stawia to wiele wyzwań m.in przed systemem edukacji - jak prawidłowo rozpoznawać prace stworzone samodzielnie przez studentów? Jak uchronić ludzi przed popadnięciem w lenistwo i wyręczaniem się LLM w wielu zadaniach, zamiast pobudzać własną kreatywność i wyobraźnię? Jak uniknąć korporacyjnego monopolu firm, mających odpowiednie zaplecze technologiczne do szkolenia modeli LLM, i narzucających swoje rozwiązania innym? Jak rozwiązać prawny problem własności intelektualnej danych, na których uczono model?&lt;/p&gt;
&lt;p&gt;Technologia ewoluuje, ale rozwój społeczny nie nadąża za tymi zmianami. Nowe czasy przynoszą nowe narzędzia, które musimy zaakceptować i nauczyć się z nimi funkcjonować. Pewne zawody znikną, pojawią się nowe, wymagające współpracy z narzędziami takimi jak LLM.&lt;/p&gt;
&lt;p&gt;Warto jednak zachować zdrowy rozsądek a przede wszystkim zrozumieć, z czym mamy do czynienia.&lt;/p&gt;
&lt;p&gt;Jako zawodowy analityk danych i programista nie boję się o pracę w kontekście modeli LLM - bardzo mnie cieszy, że dostaniemy tak przydatne narzędzie. Boję się natomiast reakcji ludzi i sposobu, w jaki będą oni korzystać z LLM-mów: często niezgodnie z przeznaczeniem i ze szkodą dla samych siebie, oraz swoich organizacji, czy instytucji.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
