<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>reinforcement learning | NeuraSYS</title>
    <link>https://maddataanalyst.github.io/pl/tag/reinforcement-learning/</link>
      <atom:link href="https://maddataanalyst.github.io/pl/tag/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>reinforcement learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>pl</language><lastBuildDate>Sat, 01 Apr 2023 21:36:41 +0100</lastBuildDate>
    <image>
      <url>https://maddataanalyst.github.io/media/icon_hu5b489458e36ca6f814edb4aedf2e84e5_21223_512x512_fill_lanczos_center_3.png</url>
      <title>reinforcement learning</title>
      <link>https://maddataanalyst.github.io/pl/tag/reinforcement-learning/</link>
    </image>
    
    <item>
      <title>Wykorzystanie uczenia ze wzmocnieniem w problemach dyskretnej alokacji zasobów w zarządzaniu projektami – eksperyment symulacyjny</title>
      <link>https://maddataanalyst.github.io/pl/publication/utilization_of_drl_for_management/</link>
      <pubDate>Sat, 01 Apr 2023 21:36:41 +0100</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/utilization_of_drl_for_management/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;results&#34; srcset=&#34;
               /media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_4b43ac134a283f7edcd6dcea7bc7885b.webp 400w,
               /media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_25d5b040907b0190a9c522d429dc3dfe.webp 760w,
               /media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://maddataanalyst.github.io/media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_4b43ac134a283f7edcd6dcea7bc7885b.webp&#34;
               width=&#34;640&#34;
               height=&#34;285&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wszystko jest grą: przypadki użycia uczenia ze wzmocnieniem poza grami</title>
      <link>https://maddataanalyst.github.io/pl/talk/wszystko-jest-gra-przypadki-uzycia-uczenia-ze-wzmocnieniem-poza-grami/</link>
      <pubDate>Tue, 21 Jun 2022 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/wszystko-jest-gra-przypadki-uzycia-uczenia-ze-wzmocnieniem-poza-grami/</guid>
      <description>&lt;p&gt;Uczenie ze wzmocnieniem (RL) zwykle kojarzone jest z grami, takimi jak klasyczne Atari, szachy czy Go. Wiele firm i osób związanych z biznesem zakłada, że RL ograniczony jest wyłącznie do tego rodzaju przypadków. Tymczasem twierdzenie to jest dalekie od prawdy – w przypadku sekwencyjnych problemów decyzyjnych, wystarczy niewiele wysiłku, by przeformułować je, do modelowania z użyciem RL. Prezentacja pokazuje kilka realnych problemów biznesowych rozwiązanych właśnie w taki sposób.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ReLeX - Eksperymenty Uczenia ze wzmocnieniem</title>
      <link>https://maddataanalyst.github.io/pl/project/relex/</link>
      <pubDate>Tue, 21 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/project/relex/</guid>
      <description>&lt;p&gt;Seria publikacji, projektów i badań związanych z algorytmami uczenia ze wzmocnieniem&lt;/p&gt;
&lt;p&gt;Strona główna projektu i powiązanych eksperymentów: &lt;a href=&#34;https://github.com/maddataanalyst/relex&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/maddataanalyst/relex&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
