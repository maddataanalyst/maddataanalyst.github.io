<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NeuraSYS</title>
    <link>https://maddataanalyst.github.io/pl/</link>
      <atom:link href="https://maddataanalyst.github.io/pl/index.xml" rel="self" type="application/rss+xml" />
    <description>NeuraSYS</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>pl</language><lastBuildDate>Fri, 14 Apr 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://maddataanalyst.github.io/media/icon_hu5b489458e36ca6f814edb4aedf2e84e5_21223_512x512_fill_lanczos_center_3.png</url>
      <title>NeuraSYS</title>
      <link>https://maddataanalyst.github.io/pl/</link>
    </image>
    
    <item>
      <title>ChatGPT mnie okłamał! - czyli o tym, jak nie oceniać modeli językowych</title>
      <link>https://maddataanalyst.github.io/pl/post/rozne/chat_gpt_klamie/</link>
      <pubDate>Fri, 14 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/post/rozne/chat_gpt_klamie/</guid>
      <description>&lt;h2 id=&#34;wstęp&#34;&gt;Wstęp&lt;/h2&gt;
&lt;p&gt;Wyobraźnię wielu osób rozbudza w ostatnim czasie ChatGPT: cudowne dzieło firmy OpenAI, demonstrujące niesamowite umiejętności rozumienia języka naturalnego i przetwarzania informacji. Internet co chwila obiegają wieści, o zaskakujących i błyskotliwych odpowiedziach, a także o  zdolnościach pisania kodu.&lt;/p&gt;
&lt;p&gt;Jednocześnie słyszy się też o błędach popełnionych przez ChatGPT, konstruowanych “fałszywych oskarżeniach” pod adresem różnych osób (&lt;a href=&#34;https://www.bbc.com/news/technology-65202597&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;przykład sprawy burmistrza z Autstralii&lt;/a&gt;), oraz idiotyzmach i nielogicznościach jego wypowiedzi.&lt;/p&gt;
&lt;p&gt;Z zaskoczeniem obserwuję co najmniej trzy postawy w stosunku do Chatu GPT:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Traktowanie go jako “mądrzejszej wyszukiwarki” Google&lt;/strong&gt; - część osób reprezentujących ten pogląd uważa, że ChatGPT jest po prostu &amp;ldquo;językowym opakowaniem&amp;rdquo; na wyszukiwarkę treści;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hurraoptymizm&lt;/strong&gt; i przekonanie, że mamy do czynienia z &amp;ldquo;prawdziwym AI&amp;rdquo;, które zrewolucjonizuje każdy element życia - takie podejście przeważa wśród technologicznych entuzjastów, korporacyjnych managerów i niektórych osób zainteresowanych &amp;ldquo;AI&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Silny sceptycyzm lub wręcz strach przed utratą pracy&lt;/strong&gt; i zastąpieniem przez nowy wynalazek - takie głosy dochodzą m.in. z grona programistów, obserwujących możliwości Chatu GPT, modelu CODEX, czy Github Copilot-a.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Wiele osób, zupełnie nie zdaje sobie sprawy, czym tak naprawdę jest ChatGPT i pokrewne rozwiązania. Co za tym idzie: dlaczego działają tak, jak działają i dlaczego się mylą. Spróbujmy odpowiedzieć na to pytanie.&lt;/p&gt;
&lt;h2 id=&#34;uczenie-maszynowe&#34;&gt;Uczenie maszynowe&lt;/h2&gt;
&lt;p&gt;ChatGPT należy do bardzo szerokiego grona dużych modeli językowych (ang. LLM - &lt;strong&gt;large language models&lt;/strong&gt;), algorytmów uczenia maszynowego (ML - ang. &lt;strong&gt;machine learning&lt;/strong&gt; znanych od dawna i stanowiących jedna z poddziedzin badań nad sztuczną inteligencją. Powstało wiele definicji tego zagadnienia, myślę, że możemy w tym miejscu przytoczyć dwie.&lt;/p&gt;
&lt;p&gt;Pierwszą z nich jest określenie terminu “uczenie się”, sformułowane przez Herberta Simona - laureata nagrody Nobla w dziedzinie ekonomii, jednego z pionierów badań nad SI.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Uczenie się oznacza takie zmiany adaptacyjne w systemie, iż jest on w stanie lepiej wykonać w przyszłości takie same zadania lub zadania należące do tej samej kategorii.
Simon, H. A. (1983). Why should machines learn?. W &lt;em&gt;Machine learning&lt;/em&gt;  (pp. 25-37). Morgan Kaufmann.
(tł. własne)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Drugą definicją jest ta sformułowana przez wybitnego polskiego naukowca, autora znakomitej książki “Systemy Uczące się”, Pawła Cichosza:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Uczeniem się systemu jest każda autonomiczna zmiana w systemie zachodząca na podstawie
doświadczeń, która prowadzi do poprawy jakości jego działania.
Cichosz, P. (2007) Systemy uczące się. Wyd. 2. Warszawa: Wydawnictwa Naukowo-Techniczne&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;W obu tych definicjach widzimy łączące je, ważne punkty:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Stopniowe nabywanie doświadczenia&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wykorzystywanie tego doświadczenia&lt;/strong&gt;, do stopniowej poprawy działania systemu.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autonomiczny charakter zmian&lt;/strong&gt; - to oznacza, że system sam reguluje sposób wykorzystania zgromadzonej wiedzy i nie wymaga przeprogramowywania przez człowieka.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tak, w ogromnym skrócie, wygląda działanie większości systemów uczenia maszynowego. Wiele z nich, w tym modele językowe, uczymy w sposób bardzo podobny do tego, jak uczą się ludzie:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pokazujemy przykładowe dane (pytania), wraz z odpowiedziami.&lt;/li&gt;
&lt;li&gt;Pozwalamy algorytmowi przedstawić własne odpowiedzi.&lt;/li&gt;
&lt;li&gt;Weryfikujemy wynik z “kluczem” (poprawnymi odpowiedziami), dając sygnał zwrotny: “dobrze/źle”, dzięki czemu system koryguje swoje zachowanie.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph LR
	pytania[pytania lub materiał] --przekazanie--&gt; algorytm
	popr[poprawne odpowiedzi] --&gt; weryfikacja
	subgraph uczenie
		algorytm
		odp[proponowane odpowiedzi]
		weryfikacja
		algorytm --udziela--&gt; 	odp --&gt; weryfikacja
		weryfikacja --sygnał błędu i poprawa--&gt; algorytm
	end
&lt;/div&gt;
&lt;p&gt;Pokazany wyżej proces nosi nazwę “uczenia nadzorowanego” i jest jednym z wielu sposobów szkolenia modeli ML.&lt;/p&gt;
&lt;h2 id=&#34;modele-językowe&#34;&gt;Modele językowe&lt;/h2&gt;
&lt;p&gt;Modele językowe, do których należy ChatGPT, Bard i podobne wpisują się w opisany schemat. W ich przypadku, uczenie polega na pokazywaniu zdań z języka naturalnego, wraz z ich kontekstem i np. kategorią tematyczną, do której należą. Algorytm uczy się, jakie sekwencje słów, zdań, akapitów i paragrafów, opisują dane zagadnienia. Podział na pytania/materiał do nauki i proponowane odpowiedzi może w tym przypadku wyglądać następująco:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Zadanie&lt;/th&gt;
&lt;th&gt;Pytanie&lt;/th&gt;
&lt;th&gt;Poprawne odpowiedzi&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Jakie powinno być następne słowo?&lt;/td&gt;
&lt;td&gt;Ala ma&lt;/td&gt;
&lt;td&gt;kota&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Bitwa pod Grunwaldem rozegrała się w&lt;/td&gt;
&lt;td&gt;1410 roku&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1410 r.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AD 1410&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Do jakiej kategorii należy zdanie?&lt;/td&gt;
&lt;td&gt;Na giełdzie zapanowały ponure nastroje, kursy akcji lecą w dół.&lt;/td&gt;
&lt;td&gt;Ekonomia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Finanse&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Giełda&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Prezydent wygłosił wspaniałe przemówienie, które wzmocni jego pozycję w nadchodzących wyborach.&lt;/td&gt;
&lt;td&gt;Polityka&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Publicystyka&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Odpowiedz na pytanie pełnym zdaniem.&lt;/td&gt;
&lt;td&gt;Ile kół ma typowy samochód?&lt;/td&gt;
&lt;td&gt;Typowy samochód ma 4 koła.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Samochód ma cztery koła.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Auta mają po 4 koła.&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;…&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Jak widać, wiele pytań/zadań ma więcej niż jedną poprawną odpowiedź. Zazwyczaj można ją sformułować na kilka sposobów, w danym języku. Zdarza się też, że treści mogą być wzajemnie sprzeczne (&lt;em&gt;Ala ma kota, Ala ma bzika, Ala ma fioła&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Co bardzo ważne - ChatGPT i inne modele z jego rodziny &lt;strong&gt;uczą się operowania językiem naturalnym&lt;/strong&gt; przez analizę wielu zdań i wypowiedzi. Tymczasem wiele postów/komentarzy i opinii jest wzajemnie sprzecznych, zwłaszcza gdy Internauci wyrażają w nich swoje opinie. Zadaniem LLM-ów jest formułować wypowiedzi na piśmie, podobnie jak robi to człowiek przy klawiaturze, &lt;strong&gt;nie są natomiast encyklopediami ani bazą wiedzy symbolicznej&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Gdy zaglądasz do encyklopedii, szukasz zazwyczaj po indeksie (np. litera “u” → uczenie maszynowe) lub w danej kategorii (np. kategoria nauki ścisłe → litera “u” → uczenie maszynowe).&lt;/p&gt;
&lt;p&gt;Modele językowe są uczone na kategoriach zdań, owszem (np. zdania z zakresu polityki lub ekonomii), ale ich zadaniem jest formułowanie płynnych wypowiedzi na dany temat, a nie poszukiwania encyklopedyczne (z małymi wyjątkami, patrz niżej 🙂).&lt;/p&gt;
&lt;p&gt;W jaki sposób te modele mogą rozumieć język pisany? Istnieje wiele sposobów szkolenia, ale jednym z nich są tzw. mechanizmy uwagi, stanowiące podwaliny architektury o znajomo brzmiącej nazwie “Transformery”.&lt;/p&gt;
&lt;h2 id=&#34;mechanizm-uwagi-i-transformery&#34;&gt;Mechanizm uwagi i transformery&lt;/h2&gt;
&lt;p&gt;Człowiek posługujący się dowolnym językiem, zapoznając się z wypowiedzią, buduje w swojej głowie “drzewo zależności” - co zdanie opisuje, w jakim czasie, co jest podmiotem, a co orzeczeniem. Każdy język rządzi się swoimi prawami, język angielski i pokrewne mają co prawda pod pewnymi względami przewagę (ograniczona odmiana słów w porównaniu np. do języka polskiego), ale zasada działania jest bardzo podobna.&lt;/p&gt;
&lt;p&gt;Spójrz na poniższe zdanie:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Kobieta usiadła na ławce i rozglądała się po parku.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Kto usiadł? &lt;em&gt;Kobieta.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Na czym usiadła? &lt;strong&gt;Na ławce&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Kto się rozglądał - kobieta, czy ławka? &lt;strong&gt;Kobieta&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Dla osoby znającej język polski takie zależności są oczywiste. Obcokrajowcy, oraz systemy językowe jak ChatGPT muszą je poznać. Ludzie uczą się na kursach gramatyki, czasów, stron i trybów, robiąc ćwiczenia i rozmawiając z lektorami.&lt;/p&gt;
&lt;p&gt;ChatGPT i modele językowe przerabiają miliony podobnych przykładów, dostając informację zwrotną, czy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Prawidłowo rozpoznały kontekst;&lt;/li&gt;
&lt;li&gt;Wygenerowane przez nie wypowiedzi są podobne do używanych w danym języku.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Mechanizm uwagi (ang. &lt;strong&gt;attention&lt;/strong&gt; nazywany też przez mechanizmem atencji pozwala algorytmom brać pod uwagę dotychczasowy kontekst zdania i wpływ poszczególnych jego części na to, co ma być dalej (następne słowo lub zdanie), lub na analizę tematu/zagadnienia (klasyfikacja).&lt;/p&gt;
&lt;p&gt;Mechanizmy uwagi w sztucznych sieciach neuronowych pełnią zbliżoną rolę do pól recepcyjnych i “uwagi konkurencyjnej” w organizmach biologicznych - skupiają system na wybranym kawałku otoczenia, pozwalając analizować kontekst zachodzących zdarzeń.&lt;/p&gt;
&lt;p&gt;Diagram poniżej pokazuje bardzo uproszczony mechanizm działania uwagi dla przykładowego zdania. Gwiazdki wskazują podmiot zdania: jest nim &lt;em&gt;kobieta&lt;/em&gt; i niewątpliwie dalsze elementy zdania będą odnosić się do niej, jako głównej “bohaterki”.&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;graph
	subgraph zdanie
	  s1[słowo 1: *Kobieta*] --&gt; s2[słowo 2: usiadła] --&gt; s3[słowo 3: na] --&gt; s4[słowo 4: ławce] --???--&gt; s5[słowo 5: ?]
	end
	subgraph reprezentacja
		s1 --&gt; sym1[*symbol1*]
		s2 --&gt; sym2[symbol2]
		s3 --&gt; sym3[symbol3]
		s4 --&gt; sym4[symbol4]
		sym1 --&gt; sym2 --&gt; sym3 --&gt; sym4
	end
	subgraph &#34; &#34;
		sym1 --*waga1*--&gt;oc
		sym2 --waga2--&gt;oc
		sym3 --waga3--&gt;oc
		sym4 --waga4--&gt;oc
		oc[ocena kontekstu] --predykcja--&gt; s5
	end
&lt;/div&gt;
&lt;p&gt;Wiele zagnieżdżonych mechanizmów uwagi, działających wspólnie z dodatkowymi fragmentami sieci składają się na architekturę zwaną “Transformerem”, która pozwala przetwarzać nawet bardzo długie sekwencje.&lt;/p&gt;
&lt;p&gt;Warto pamiętać też, że algorytmy uczenia maszynowego nie przetwarzają języka bezpośrednio - słowa są zmieniane na reprezentację numeryczną w mechanizmie zwanym “osadzaniem” (ang. &lt;strong&gt;embedding&lt;/strong&gt;) - który pozwala przedstawiać słowa jako wektory liczb. W procesie uczenia następuje szereg operacji probabilistycznych i matematycznych, mających odzwierciedlić uczone treści. Jeśli wszystko idzie zgodnie z planem, pojęcia bliskoznaczne znajdują się wówczas niedaleko siebie na płaszczyźnie numerycznej. Dodatkowo, możliwe są na nich operacje arytmetyczne, prowadzące do zaskakująco trafnych przekształceń jak np:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;król - mężczyzna  + kobieta ~ królowa&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Przykład umiejscowienia słów jako reprezentacji numerycznych znajduje się poniżej:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;word_transforms&#34; srcset=&#34;
               /pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_85b1c5b99387c35f1ccebfbf78af2673.webp 400w,
               /pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_bb1d28375b6638e7b81dc2d7a4483673.webp 760w,
               /pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://maddataanalyst.github.io/pl/post/rozne/chat_gpt_klamie/word_transforms_hu3f224db61f4a75d1fcc2998676a9be92_9636_85b1c5b99387c35f1ccebfbf78af2673.webp&#34;
               width=&#34;532&#34;
               height=&#34;192&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Jakiś czas temu, miałem przyjemność opowiadać podczas konferencji Data Science Summit o dokładnym mechanizmie wykorzystania osadzeń/embedding’ów w zadaniach klasyfikacji, lub rekomendacji. Materiały z wykładu znajdziesz &lt;a href=&#34;https://filip-wojcik.com/uploads/embeddings_other_than_nlp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutaj&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ChatGPT został nauczony na ogromnych zbiorach tekstów z sieci (m. in. &lt;a href=&#34;https://paperswithcode.com/dataset/bookcorpus&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BooksCorpus&lt;/a&gt;, &lt;a href=&#34;https://www.eleuther.ai/projects/owt2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebText2&lt;/a&gt;) oraz tzw. &lt;a href=&#34;https://commoncrawl.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Common Crawl&lt;/a&gt;. Jest to zbiór danych składający się z miliardów stron internetowych, które są regularnie przeszukiwane i indeksowane przez roboty Google i innych podobnych firm. OpenAI, organizacja odpowiedzialna za stworzenie ChatGPT, wykorzystała wersję z 2019 roku tego zbioru, która składała się z ponad 40 terabajtów danych tekstowych. Zbiór zawierał wiele różnych typów tekstów, w tym artykuły, recenzje, wpisy na blogach, a nawet fora internetowe.&lt;/p&gt;
&lt;p&gt;Co ważne: wiele tekstów i wypowiedzi krążących w Internecie jest wzajemnie sprzeczna. Ludzie podają nieprawdziwe informacje, odpowiadają nie na temat, tworzą teorie spiskowe…. Wszystko to, wraz z kontekstem wypowiedzi stało się materiałem uczącym dla LLM.&lt;/p&gt;
&lt;h2 id=&#34;chodząca-encyklopedia&#34;&gt;Chodząca encyklopedia?&lt;/h2&gt;
&lt;p&gt;Powyższy, mocno uproszczony opis, powinien dać nam pewien ogląd czym są i jak działają algorytmy pokrewne do ChatuGPT. W najprostszym ujęciu, są to modele uczenia maszynowego, bazujące na wielu przykładach, jakie im przedstawiono, nauczone generowania nowych wypowiedzi, będących odpowiedziami na konkretne pytania, lub w sposób swobodny.&lt;/p&gt;
&lt;p&gt;Swoje teksty konstruują za każdym razem od nowa, kierując się mechanizmami kontekstu i uwagi, pozwalającymi na rozpoznanie tematu “dyskusji”, dotąd wypowiedzianych kwestii itd. W tym procesie starają się upodobnić własne dzieła do tych, które były im przedstawione jako charakterystyczne dla danego języka.&lt;/p&gt;
&lt;p&gt;W tym kontekście, ChatGPT i modele LLM &lt;strong&gt;nie mogą być&lt;/strong&gt; uznawane za “chodzące encyklopedie”, albo wyszukiwarki treści. Nie posiadają ustrukturyzowanej wiedzy encyklopedycznej, nie są uwarunkowane na udzielanie &amp;ldquo;poprawnych odpowiedzi&amp;rdquo; - generują słowa, które mają być spójne z językiem, w jakim prowadzona jest konwersacja, kontekstem rozmowy, jej tematem, itp. Z tego względu, mogą mijać się z prawdą.&lt;/p&gt;
&lt;p&gt;W chwili pisania tego tekstu, powstają już wtyczki i rozszerzenia, pozwalające modelom LLM łączyć się z bazami wiedzy, posługiwać się wyszukiwarkami treści, albo narzędziami matematycznymi takimi jak Wolfram Alpha do wykonywania &lt;strong&gt;celowo poprawnych obliczeń&lt;/strong&gt; lub wyszukiwania encyklpedycznych informacji.&lt;/p&gt;
&lt;p&gt;Nie zmienia to jednak faktu, że w swoim jądrze modele LLM są modelami &lt;strong&gt;językowymi&lt;/strong&gt; a nie chodzącymi encyklopediami. Z tego względu “oskarżanie” ich o popełnienie błędu albo generowanie nieprawidłowych treści jest zupełnym niezrozumieniem przeznaczenia tych narzędzi.&lt;/p&gt;
&lt;h2 id=&#34;sztuczne-języki&#34;&gt;Sztuczne języki&lt;/h2&gt;
&lt;p&gt;Mając na uwadze powyższy opis, można sobie zadać pytanie: dlaczego ChatGPT tak dobrze programuje i pisze kod relatywnie sprawnie?&lt;/p&gt;
&lt;p&gt;Słowo “język” w odniesieniu do dialektów programistycznych jest uzasadnione. Języki programowania to symboliczne, sztuczne języki, o charakterze utylitarnym, czyli służącym konkretnemu celowi - tworzeniu działających aplikacji i algorytmów w sposób imperatywny, czyli jednoznacznie wskazujący na operacje do wykonania.&lt;/p&gt;
&lt;p&gt;W przeciwieństwie do ludzkich języków, języki programowania:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;są dużo bardziej &lt;strong&gt;jednoznaczne&lt;/strong&gt;, pozbawione zbędnych “ozdobników” ;&lt;/li&gt;
&lt;li&gt;mają &lt;strong&gt;ściśle określoną składnię.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Dodatkowo: kod udostępniony publicznie w Internecie bardzo często jest napisany poprawnie i działa.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Jeśli dodamy do siebie powyższe trzy punkty:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;jednoznaczność + czytelny, sformalizowany język + dużo poprawnych i prawidłowych przykładów&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;otrzymujemy &lt;strong&gt;znakomity zestaw wypowiedzi uczących dla LLM&lt;/strong&gt;. W przeciwieństwie do forów, blogów i komentarzy, gdzie każdy wyraża swoje opinie - “wypowiedzi” pisane w językach programowania są dużo bardziej zwarte, poprawne i jednoznaczne.&lt;/p&gt;
&lt;h2 id=&#34;co-dalej&#34;&gt;Co dalej?&lt;/h2&gt;
&lt;p&gt;Niewątpliwie ChatGPT i pokrewne modele LLM stanową rewolucję w dziedzinie praktycznych zastosowań AI. Pozwolą na automatyzację wielu zadań, generowanie treści, do tej pory zarezerwowanych dla ludzkich twórców, w tym także kodu źródłowego aplikacji.&lt;/p&gt;
&lt;p&gt;Stawia to wiele wyzwań m.in przed systemem edukacji - jak prawidłowo rozpoznawać prace stworzone samodzielnie przez studentów? Jak uchronić ludzi przed popadnięciem w lenistwo i wyręczaniem się LLM w wielu zadaniach, zamiast pobudzać własną kreatywność i wyobraźnię? Jak uniknąć korporacyjnego monopolu firm, mających odpowiednie zaplecze technologiczne do szkolenia modeli LLM, i narzucających swoje rozwiązania innym? Jak rozwiązać prawny problem własności intelektualnej danych, na których uczono model?&lt;/p&gt;
&lt;p&gt;Technologia ewoluuje, ale rozwój społeczny nie nadąża za tymi zmianami. Nowe czasy przynoszą nowe narzędzia, które musimy zaakceptować i nauczyć się z nimi funkcjonować. Pewne zawody znikną, pojawią się nowe, wymagające współpracy z narzędziami takimi jak LLM.&lt;/p&gt;
&lt;p&gt;Warto jednak zachować zdrowy rozsądek a przede wszystkim zrozumieć, z czym mamy do czynienia.&lt;/p&gt;
&lt;p&gt;Jako zawodowy analityk danych i programista nie boję się o pracę w kontekście modeli LLM - bardzo mnie cieszy, że dostaniemy tak przydatne narzędzie. Boję się natomiast reakcji ludzi i sposobu, w jaki będą oni korzystać z LLM-mów: często niezgodnie z przeznaczeniem i ze szkodą dla samych siebie, oraz swoich organizacji, czy instytucji.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wykorzystanie uczenia ze wzmocnieniem w problemach dyskretnej alokacji zasobów w zarządzaniu projektami – eksperyment symulacyjny</title>
      <link>https://maddataanalyst.github.io/pl/publication/utilization_of_drl_for_management/</link>
      <pubDate>Sat, 01 Apr 2023 21:36:41 +0100</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/utilization_of_drl_for_management/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;results&#34; srcset=&#34;
               /media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_4b43ac134a283f7edcd6dcea7bc7885b.webp 400w,
               /media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_25d5b040907b0190a9c522d429dc3dfe.webp 760w,
               /media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://maddataanalyst.github.io/media/results_relex_hu171ca6241ab70b0b57e5c356201b057b_20674_4b43ac134a283f7edcd6dcea7bc7885b.webp&#34;
               width=&#34;640&#34;
               height=&#34;285&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wszystko jest grą: przypadki użycia uczenia ze wzmocnieniem poza grami</title>
      <link>https://maddataanalyst.github.io/pl/talk/wszystko-jest-gra-przypadki-uzycia-uczenia-ze-wzmocnieniem-poza-grami/</link>
      <pubDate>Tue, 21 Jun 2022 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/wszystko-jest-gra-przypadki-uzycia-uczenia-ze-wzmocnieniem-poza-grami/</guid>
      <description>&lt;p&gt;Uczenie ze wzmocnieniem (RL) zwykle kojarzone jest z grami, takimi jak klasyczne Atari, szachy czy Go. Wiele firm i osób związanych z biznesem zakłada, że RL ograniczony jest wyłącznie do tego rodzaju przypadków. Tymczasem twierdzenie to jest dalekie od prawdy – w przypadku sekwencyjnych problemów decyzyjnych, wystarczy niewiele wysiłku, by przeformułować je, do modelowania z użyciem RL. Prezentacja pokazuje kilka realnych problemów biznesowych rozwiązanych właśnie w taki sposób.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ReLeX - Eksperymenty Uczenia ze wzmocnieniem</title>
      <link>https://maddataanalyst.github.io/pl/project/relex/</link>
      <pubDate>Tue, 21 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/project/relex/</guid>
      <description>&lt;p&gt;Seria publikacji, projektów i badań związanych z algorytmami uczenia ze wzmocnieniem&lt;/p&gt;
&lt;p&gt;Strona główna projektu i powiązanych eksperymentów: &lt;a href=&#34;https://github.com/maddataanalyst/relex&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/maddataanalyst/relex&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Głębokie sieci neuronowe, jako systemy rekomendacyjne: architektura, zastosowania, możliwości. Studium przypadku.</title>
      <link>https://maddataanalyst.github.io/pl/publication/deep_learning_as_recommenders/</link>
      <pubDate>Mon, 01 Mar 2021 21:36:41 +0100</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/deep_learning_as_recommenders/</guid>
      <description>&lt;p&gt;Rozwój rynku internetowych usług cyfrowych pod koniec XX wieku doprowadził do gwałtownego wzrostu znaczenia spersonalizowanych rekomendacji konsumenckich. Liczba produktów oraz baza klientów na platformach takich jaki Allegro czy Amazon, wykracza wielokrotnie poza skalę stosowaną w klasycznym marketingu [Jones, 2013]. Z tego względu, coraz większego znaczenia zaczęły nabierać zautomatyzowane systemy rekomendacyjne, analizujące zachowania i preferencje klientów. Do najnowocześniejszych rozwiązań stosowanych w tym zakresie można zaliczyć głębokie sieci neuronowe typu autoencoder [Sedhain i in., 2015] i im pokrewne. Stanowią one kolejny krok w ewolucji tzw. filtracji kolaboratywnej (ang. collaborative filtering) po raz pierwszy zastosowanej na platformie Netflix [Zhang i in., 2016]. Uzyskiwane przez nie wyniki są statystycznie istotnie lepsze od metod klasycznych.&lt;/p&gt;
&lt;p&gt;Publikacja preznetuje przykłady architektury, implementacji i możliwości systemów wykorzystujących głębokie sieci neuronowe, w konkretnych przypadkach biznesowych – na bazie danych sprzedaży platformy Amazon z 2018r.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Literatura:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Biancalana, C., Gasparetti, F., Micarelli, A., Miola, A., &amp;amp; Sansonetti, G. (2011). Context-aware movie recommendation based on signal processing and machine learning. In Proceedings of the 2nd Challenge on Context-Aware Movie Recommendation (pp. 5–10).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Brynjolfsson, E., &amp;amp; McAfee, A. (2014). The second machine age: Work, progress, and prosperity in a time of brilliant technologies. WW Norton &amp;amp; Company.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Canny, J. (2002). Collaborative filtering with privacy via factor analysis. Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 238–245.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., Anderson, G., Corrado, G., Chai, W., Ispir, M., &amp;amp; others. (2016). Wide &amp;amp; deep learning for recommender systems. Proceedings of the 1st Workshop on Deep Learning for Recommender Systems, 7–10.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Goldberg, K., Roeder, T., Gupta, D., &amp;amp; Perkins, C. (2001). Eigentaste: A constant time collaborative filtering algorithm. Information Retrieval, 4(2), 133–151.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Guo, H., Tang, R., Ye, Y., Li, Z., &amp;amp; He, X. (2017). DeepFM: a factorization-machine based neural network for CTR prediction. ArXiv Preprint ArXiv:1703.04247.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Hornik, K., Stinchcombe, M., White, H., &amp;amp; others. (1989). Multilayer feedforward networks are universal approximators. Neural Networks, 2(5), 359–366.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Koren, Y., Bell, R., &amp;amp; Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30–37.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Kuchaiev, O., &amp;amp; Ginsburg, B. (2017). Training deep autoencoders for collaborative filtering. ArXiv Preprint ArXiv:1708.01715.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Lian, J., Zhou, X., Zhang, F., Chen, Z., Xie, X., &amp;amp; Sun, G. (2018). xdeepfm: Combining explicit and implicit feature interactions for recommender systems. Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining, 1754–1763.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Liang, D., Krishnan, R. G., Hoffman, M. D., &amp;amp; Jebara, T. (2018). Variational autoencoders for collaborative filtering. Proceedings of the 2018 World Wide Web Conference, 689–698.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Salakhutdinov, R., Mnih, A., &amp;amp; Hinton, G. (2007). Restricted Boltzmann machines for collaborative filtering. Proceedings of the 24th International Conference on Machine Learning, 791–798.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Schafer, J., Frankowski, D., Herlocker, J., &amp;amp; Sen, S. (2007). Collaborative Filtering Recommender Systems. In The Adaptive Web (Vol. 4321, pp. 291–324)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Sedhain, S., Menon, A. K., Sanner, S., &amp;amp; Xie, L. (2015). Autorec: Autoencoders meet collaborative filtering. Proceedings of the 24th International Conference on World Wide Web, 111–112.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Wójcik, F., &amp;amp; Górnik, M. (2020). Improvement of e-commerce recommendation systems with deep hybrid collaborative filtering with content: A case study. Econometrics, 24(3), 37–50.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Wu, Y., DuBois, C., Zheng, A. X., &amp;amp; Ester, M. (2016). Collaborative denoising auto-encoders for top-n recommender systems. Proceedings of the Ninth ACM International Conference on Web Search and Data Mining, 153–162.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Zhang, N., Ding, S., Zhang, J., &amp;amp; Xue, Y. (2018). An overview on Restricted Boltzmann Machines. Neurocomputing, 275, 1186–1199&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Przełamać nieufność – metody zapewniania przejrzystości modeli uczenia maszynowego w zastosowaniach ekonomicznych</title>
      <link>https://maddataanalyst.github.io/pl/publication/beyond_a_barrier_of_mistrust/</link>
      <pubDate>Mon, 01 Mar 2021 21:36:41 +0100</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/beyond_a_barrier_of_mistrust/</guid>
      <description>&lt;p&gt;Wraz z upowszechnieniem się stosowania uczenia maszynowego, jako zestawu technik i narzędzi do rozwiązywania problemów biznesowych, zaczął narastać problem zapewnienia ich interpretowalności i budowania zaufania do generowanych predykcji [Gunning i in., 2019]. Zjawisko to nasiliło się, po osiągnięciu (w niektórych dziedzinach) przez głębokie sieci neuronowe wyników, przekraczających możliwości człowieka, przy jednoczesnym braku prostych metod ustalenia źródeł podejmowanych przez nie decyzji [Holzinger, 2018]. Wejście w życie przepisów nakładających obowiązek ścisłej ochrony danych osobowych i zapewnienia transparentności procesu ich przetwarzania (RODO) stały się przyczynkiem do dyskusji nad koncepcją XAI – „możliwych do wyjaśnienia metod sztucznej inteligencji” (ang. eXplainable Artificial Intelligence) [Holzinger i in., 2018]. Obszary życia społecznego, o szczególnie istotnym znaczeniu i wrażliwości (jak np. medycyna, wymiar sprawiedliwości czy rynki finansowe), w których wykorzystywane jest uczenie maszynowe, powinny mieć dostęp do technik pogłębionej analizy otrzymywanych wyników. Niektórzy autorzy postulują nawet, by zaprzestać używania algorytmów o wyjątkowo skomplikowanej wewnętrznej strukturze, w przypadku decyzji niosących ze sobą wysokie koszty potencjalnej pomyłki [Rudin, 2019].&lt;/p&gt;
&lt;p&gt;Podczas wystąpienia zaprezentowane zostaną nowoczesne koncepcje i metody, mające na celu budowanie większego zaufania do inteligentnych systemów komputerowych, poprzez przedstawianie ich interpretacji, czy objaśnień. Przybliżone zostaną m.in. SHAP (ang. shapley additive explanations), LIME (ang. locally interpretable model-agnostic explanations), Anchor i metoda granicy decyzyjnej (ang. decision boundary) [Hase &amp;amp; Bansal, 2020].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Literatura:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Gunning, D., Stefik, M., Choi, J., Miller, T., Stumpf, S., &amp;amp; Yang, G. Z. (2019). XAI-Explainable artificial intelligence. Science Robotics.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Hase, P., &amp;amp; Bansal, M. (2020). Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior? arXiv preprint arXiv:2005.01831.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Holzinger, A. (2018). From machine learning to explainable AI. DISA 2018 - IEEE World Symposium on Digital Intelligence for Systems and Machines, Proceedings, January, 55–66.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Holzinger, A., Kieseberg, P., Weippl, E., &amp;amp; Tjoa, A. M. (2018). Current advances, trends and challenges of machine learning and knowledge extraction: from machine learning to explainable AI. International Cross-Domain Conference for Machine Learning and Knowledge Extraction, 1–8.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Rudin, C. (2019). Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, 1(5), 206–215.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>One concept to rule them all - uses of neural embeddings beyond natural language processing</title>
      <link>https://maddataanalyst.github.io/pl/talk/one-concept-to-rule-them-all-uses-of-neural-embeddings-beyond-natural-language-processing/</link>
      <pubDate>Thu, 18 Jun 2020 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/one-concept-to-rule-them-all-uses-of-neural-embeddings-beyond-natural-language-processing/</guid>
      <description>&lt;p&gt;The goal of this presentation and associated paper is to present results of investigation related to use of the Extreme Gradient Boosting XGBoost algorithm as a forecasting tool. The data provided by the Rossman Com-pany, with a request to design an innovative prediction method, has been used as a base for this case study. The data contains details about micro- and macro-environment, as well as turnover of 1115 stores. Performance of the algorithm was compared to classical forecasting models SARIMAX and Holt-Winters, using time-series cross validation and tests for statistical importance in prediction quality dif-ferences. Metrics of root mean squared percentage error (RMSPE), Theil’s coeffi-cient and adjusted correlation coefficient were analyzed. Results where then passed to Rossman for verification on a separate validation set, via Kaggle.com platform. Study results confirmed, that XGBoost, after using proper data preparation and training method, achieves better results than classical models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improvement of e-commerce recommendation systems with deep hybrid collaborative filtering with content: A case study</title>
      <link>https://maddataanalyst.github.io/pl/publication/deep_hybrid_recommendation_system/</link>
      <pubDate>Tue, 03 Mar 2020 21:36:41 +0100</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/deep_hybrid_recommendation_system/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recommendation engines based on autoencoders</title>
      <link>https://maddataanalyst.github.io/pl/talk/recommendation-engines-based-on-autoencoders/</link>
      <pubDate>Fri, 14 Jun 2019 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/recommendation-engines-based-on-autoencoders/</guid>
      <description>&lt;p&gt;Recommendation engines are probably the most important tools for modern e-commerce organizations. As the data volumes grow larger and larger (as well as product/user base), traditional approaches based on collaborative might be not enough. During this talk I will present alternative approaches to recommendations - making use of deep stacked autoencoders.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wykorzystanie algorytmów głębokiego uczenia jako narzędzi rekomendacyjnych</title>
      <link>https://maddataanalyst.github.io/pl/project/deep_learning_recommenders/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/project/deep_learning_recommenders/</guid>
      <description>&lt;p&gt;Seria prezentacji, publikacji i wdrożonych projektów, skupiających się na algorytmach głębokiego uczenia wykorzystywanych jako systemy rekomendacyjne.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>XGBoost as a time-series forecasting tool</title>
      <link>https://maddataanalyst.github.io/pl/talk/xgboost-as-a-time-series-forecasting-tool/</link>
      <pubDate>Fri, 08 Jun 2018 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/xgboost-as-a-time-series-forecasting-tool/</guid>
      <description>&lt;p&gt;The goal of this presentation and associated paper is to present results of investigation related to use of the Extreme Gradient Boosting XGBoost algorithm as a forecasting tool. The data provided by the Rossman Com-pany, with a request to design an innovative prediction method, has been used as a base for this case study. The data contains details about micro- and macro-environment, as well as turnover of 1115 stores. Performance of the algorithm was compared to classical forecasting models SARIMAX and Holt-Winters, using time-series cross validation and tests for statistical importance in prediction quality dif-ferences. Metrics of root mean squared percentage error (RMSPE), Theil’s coeffi-cient and adjusted correlation coefficient were analyzed. Results where then passed to Rossman for verification on a separate validation set, via Kaggle.com platform. Study results confirmed, that XGBoost, after using proper data preparation and training method, achieves better results than classical models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prognozowanie z wykorzystaniem algorytmu XGBoost</title>
      <link>https://maddataanalyst.github.io/pl/project/xgboost_forecast/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/project/xgboost_forecast/</guid>
      <description>&lt;p&gt;Seria publikacji, prezentacji i wdrożeń, wykorzystujących algortym XGBoost do prognozowania szeregów czasowych.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine learning and artificial intelligence as a decision support systems for human capital management</title>
      <link>https://maddataanalyst.github.io/pl/talk/machine-learning-and-artificial-intelligence-as-a-decision-support-systems-for-human-capital-management/</link>
      <pubDate>Wed, 18 Apr 2018 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/machine-learning-and-artificial-intelligence-as-a-decision-support-systems-for-human-capital-management/</guid>
      <description>&lt;p&gt;Human capital and human resources are key success factors for multiple knowledge-based companies. Managing competences of employees is one of the most important areas for modern management science. This paper presents, an innovative algorithm based on natural language processing (NLP) and association analysis for recognition, assignment and evaluation of competences in a knowledge-rich organizations. An algorithm performs keywords extraction from applicant’s and employees resumes, which are used later on in a supervised phase. Achieved results - 71% of balanced accuracy in a case study suggest, that a system can recognize important correlations between competences and assigned projects.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prognozowanie dziennych obrotów przedsiębiorstwa za pomocą algorytmu XGBoost - studium przypadku</title>
      <link>https://maddataanalyst.github.io/pl/publication/xgboost_turnover/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/xgboost_turnover/</guid>
      <description>&lt;p&gt;Celem niniejszej publikacji jest przedstawienie innowacyjnego zastosowania algorytmu XGBoost (ang. Extreme Gradient Boosting) do prognozowania obrotów przedsiębiorstwa. Pierwotnie procedura ta stworzona została jako klasyfikator i narzędzie regresji, nie zaś system prognozowania szeregów czasowych. Badania oparte na studiach przypadków wykazały jednak, iż dzięki odpowiedniej obróbce wstępnej danych i ich przygotowaniu, możliwe jest użycie omawianego algorytmu w przedstawionym kontekście.&lt;/p&gt;
&lt;p&gt;W 2016 r. firma Rossmann (zwana dalej Organizacją) upubliczniła na platformie Kaggle.com częściowo zanonimizowane dane operacyjne dotyczące swojej działalności począwszy od roku 2013, wraz z uzyskanymi obrotami (waluta oraz jednostka nieujawnione), zwracając się do globalnej społeczności analityków z prośbą o pomoc w opracowaniu innowacyjnej metody prognozowania obrotów na podstawie danych z mikro i makro otoczenia sklepów. Organizacja chciała otrzymać lepsze wyniki niż dotychczas stosowane modele oparte na metodach takich jak ARIMA/SARIMA/ARIMAX, czy model Holta-Wintersa. Udostępnione informacje zawierały szczegóły 1115 poszczególnych oddziałów, takie jak bliskość konkurenta, od ilu lat operuje on w pobliżu, jak duży asortyment posiada dana placówka, ile było aktywnych promocji, etc. oraz charakterystykę okresu kalendarzowego (święta państwowe, ferie szkolne etc.). Dane były miejscami zniekształcone, nieprawidłowe lub w oczywisty sposób sprzeczne. Mimo to, zdaniem Organizacji, możliwe było zidentyfikowanie, w oparciu o podane atrybuty, istotnych trendów i korelacji, a następnie opisanie ich za pomocą modelu predykcyjnego zdolnego ekstrapolować na przyszłość.&lt;/p&gt;
&lt;p&gt;Jest to konkretny przypadek pojedynczego podmiotu będący jednak, zdaniem autora, egzemplifikacją szerszego zagadnienia – prognozowania szeregów czasowych w oparciu o duże wolumeny danych o zróżnicowanej jakości i charakterze.&lt;/p&gt;
&lt;p&gt;Po wstępnej obróbce i eksploracji udostępnionego wolumenu, wyselekcjonowano do analizy porównawczej modele (S)ARIMA(X) oraz metodę Holta-Wintersa. Jako kryterium porównawcze wybrano metrykę średniego błędu procentowego w przedziale weryfikacji RMSPE (wskazaną jako preferowana przez Firmę Rossman), współczynnik Theila oraz skorygowany współczynnik determinacji
R2.
R2.&lt;/p&gt;
&lt;p&gt;Testy prowadzono metodą wielokrotnej walidacji krzyżowej szeregu czasowego. Uzyskane modele przesłano, za pośrednictwem platformy Kaggle.com, do Organizacji, w celu weryfikacji z użyciem zewnętrznego, walidacyjnego, zbioru danych. W każdym z przypadków, wyniki działania algorytmów porównywano testami statystycznymi na istotność różnicy metryk, z korekcją studentyzowanych przedziałów ufności Tukeya (ze względu na obecność porównań wielokrotnych).&lt;/p&gt;
&lt;p&gt;Analiza wyników przeprowadzonych badań wskazuje, iż algorytm XGBoost za każdym razem uzyskiwał, na przedmiotowym zbiorze danych, statystycznie istotnie lepsze rezultaty w porównaniu do metod klasycznych. Algorytm przeznaczony pierwotnie do pracy z danymi statycznymi został skutecznie wykorzystany w charakterze narzędzia prognozowania, dzięki zastosowaniu procesu uczenia za pomocą indeksów sezonowych oraz statycznych zmiennych niezależnych. Indeksy sezonowe oraz inne składowe trendu, zidentyfikowane przez model jako istotne, pokrywają się z manualną analizą własności szeregów, przeprowadzoną w fazie eksploracji. Jednocześnie – XGBoost zignorował wszystkie pozostałe (redundantne) indeksy i średnie ruchome, których istotności nie potwierdziła manualna analiza. Należy to uznać za zachowanie prawidłowe – algorytm wskazał te same składowe sezonowości, co klasyczne metody analizy.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting business-relevant attributes in rule-based classification</title>
      <link>https://maddataanalyst.github.io/pl/publication/business_relevant_attributes_2017/</link>
      <pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/publication/business_relevant_attributes_2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Water powered machine learning: gradient boosting machines in H2O AI</title>
      <link>https://maddataanalyst.github.io/pl/talk/water-powered-machine-learning-gradient-boosting-machines-in-h2o-ai/</link>
      <pubDate>Fri, 07 Apr 2017 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/water-powered-machine-learning-gradient-boosting-machines-in-h2o-ai/</guid>
      <description>&lt;p&gt;H2O AI is one of the most interesting out-of-the-box machine learning tools. It has plenty of algorithms implemented, those algorithms are really fast and effective and it integrates well with R and Spark. One of them is especially interesing - Gradient Boosting. Want to know more?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Decision support systems remade: (machine) learning advisers</title>
      <link>https://maddataanalyst.github.io/pl/talk/decision-support-systems-remade-machine-learning-advisers/</link>
      <pubDate>Thu, 28 Apr 2016 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/decision-support-systems-remade-machine-learning-advisers/</guid>
      <description>&lt;p&gt;Machine learning algorithms are replacement for an old-fashioned advisory systems. How we can utilize them in such a way? How white-box systems are different from black-box?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine learning - when Big Data is not enough</title>
      <link>https://maddataanalyst.github.io/pl/talk/machine-learning-when-big-data-is-not-enough/</link>
      <pubDate>Thu, 05 Nov 2015 12:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/talk/machine-learning-when-big-data-is-not-enough/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Filip Wójcik</title>
      <link>https://maddataanalyst.github.io/pl/authors/filip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://maddataanalyst.github.io/pl/authors/filip/</guid>
      <description>&lt;p&gt;Cześć!
Nazywam się Filip Wójcik i jestem analitykiem danych oraz programistą specjalizującym się w systemach uczenia maszynowego i (szeroko rozumianej) sztucznej inteligencji. W 2021r. uzyskałem tytuł doktora na Uniwersytecie Ekonomicznym we Wrocławiu, w katedrze Inteligencji Biznesowej w Zarządzaniu. W swoich badaniach naukowych skupiam się na zastosowaniach uczenia maszynowego (zwłaszcza systemów uczenia głębokiego /Deep Learning) we wspomaganiu decyzji.
Swoją pasją i zainteresowaniami w tym obszarze staram się dzielić ze studentami, pokazując możliwe kierunki rozwoju i nowe trendy. Nauczanie jest dla mnie jednym z najważniejszych aspektów zaangażowania na Uczelni.
Poza pracą i nauką – jestem pasjonatem sportów walki (posiadam stopień drugi Dan Aikido, jestem instruktorem samoobrony,  aktywnie trenuję Krav Magę), CrossFit i podróży górskich.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
